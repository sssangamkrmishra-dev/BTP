{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b78cd9",
   "metadata": {},
   "source": [
    "# Sample Drone Payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aceffd",
   "metadata": {},
   "source": [
    "Sample A — Video + Image (normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%JSON\n",
    "{\n",
    "  \"drone_id\": \"DRN-001\",\n",
    "  \"timestamp\": \"2025-10-13T03:00:12Z\",\n",
    "  \"mission_id\": \"MSN-142\",\n",
    "  \"mission_zone\": \"zone-a\",\n",
    "  \"geo\": { \"lat\": 12.971598, \"lon\": 77.594566, \"alt\": 120 },\n",
    "  \"payloads\": [\n",
    "    {\n",
    "      \"type\": \"video\",\n",
    "      \"filename\": \"drn001_fpv_001.mp4\",\n",
    "      \"mime\": \"video/mp4\",\n",
    "      \"size_bytes\": 4500000,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"checksum\": \"a1b2c3d4...\"\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"image\",\n",
    "      \"filename\": \"drn001_cam_001.jpg\",\n",
    "      \"mime\": \"image/jpeg\",\n",
    "      \"size_bytes\": 320000,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"checksum\": \"e5f6g7h8...\"\n",
    "    }\n",
    "  ],\n",
    "  \"telemetry\": { \"speed\": 12.5, \"heading\": 145.2, \"battery\": 78.4, \"signal_strength\": 82.1 },\n",
    "  \"signature\": null,\n",
    "  \"firmware_version\": \"v1.2.0\",\n",
    "  \"operator_id\": \"OP-12\",\n",
    "  \"additional_metadata\": { \"camera_model\": \"CAM-X1000\", \"frame_rate\": 30 }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5251a1",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Sample B — Encrypted nested archive (suspicious-looking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%JSON{\n",
    "  \"drone_id\": \"DRN-002\",\n",
    "  \"timestamp\": \"2025-10-13T03:05:45Z\",\n",
    "  \"mission_id\": \"MSN-143\",\n",
    "  \"mission_zone\": \"zone-c\",\n",
    "  \"geo\": { \"lat\": 13.035542, \"lon\": 77.597100, \"alt\": 85 },\n",
    "  \"payloads\": [\n",
    "    {\n",
    "      \"type\": \"archive\",\n",
    "      \"filename\": \"payload_bundle.zip\",\n",
    "      \"mime\": \"application/zip\",\n",
    "      \"size_bytes\": 4200000,\n",
    "      \"encryption\": true,\n",
    "      \"container\": true,\n",
    "      \"checksum\": \"9f8e7d6c...\"\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"text\",\n",
    "      \"filename\": \"notes.txt\",\n",
    "      \"mime\": \"text/plain\",\n",
    "      \"size_bytes\": 2048,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"checksum\": \"1234abcd...\"\n",
    "    }\n",
    "  ],\n",
    "  \"telemetry\": { \"speed\": 0.0, \"heading\": 0.0, \"battery\": 56.1, \"signal_strength\": 65.3 },\n",
    "  \"signature\": \"ed25519:abcdef012345...\",\n",
    "  \"firmware_version\": \"v1.1.9\",\n",
    "  \"operator_id\": \"OP-23\",\n",
    "  \"additional_metadata\": { \"mission_priority\": \"high\", \"notes\": \"compressed mission dataset\" }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1279ae",
   "metadata": {},
   "source": [
    "Sample C — Telemetry-only / small text (low-risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9767dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%JSON\n",
    "{\n",
    "  \"drone_id\": \"DRN-003\",\n",
    "  \"timestamp\": \"2025-10-13T03:10:03Z\",\n",
    "  \"mission_id\": \"MSN-144\",\n",
    "  \"mission_zone\": \"zone-b\",\n",
    "  \"geo\": { \"lat\": 12.967800, \"lon\": 77.601200, \"alt\": 35 },\n",
    "  \"payloads\": [\n",
    "    {\n",
    "      \"type\": \"telemetry\",\n",
    "      \"filename\": \"telemetry_snapshot.json\",\n",
    "      \"mime\": \"application/json\",\n",
    "      \"size_bytes\": 1500,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"checksum\": \"fedcba987...\"\n",
    "    }\n",
    "  ],\n",
    "  \"telemetry\": { \"speed\": 6.2, \"heading\": 220.0, \"battery\": 92.3, \"signal_strength\": 90.4 },\n",
    "  \"signature\": null,\n",
    "  \"firmware_version\": \"v1.2.3\",\n",
    "  \"operator_id\": \"OP-33\",\n",
    "  \"additional_metadata\": { \"note\": \"routine patrol\", \"weather\": \"clear\" }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9f321",
   "metadata": {},
   "source": [
    "Sample D — Mixed with large video + camera metadata (mission-critical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%JSON\n",
    "{\n",
    "  \"drone_id\": \"DRN-004\",\n",
    "  \"timestamp\": \"2025-10-13T03:15:22Z\",\n",
    "  \"mission_id\": \"MSN-145\",\n",
    "  \"mission_zone\": \"zone-a\",\n",
    "  \"geo\": { \"lat\": 12.975000, \"lon\": 77.590000, \"alt\": 200 },\n",
    "  \"payloads\": [\n",
    "    {\n",
    "      \"type\": \"video\",\n",
    "      \"filename\": \"survey_coverage_long.mp4\",\n",
    "      \"mime\": \"video/mp4\",\n",
    "      \"size_bytes\": 12500000,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"checksum\": \"aaaabbbbcccc...\"\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"image\",\n",
    "      \"filename\": \"survey_frame_2345.jpg\",\n",
    "      \"mime\": \"image/jpeg\",\n",
    "      \"size_bytes\": 550000,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"checksum\": \"ddddeeeeffff...\"\n",
    "    }\n",
    "  ],\n",
    "  \"telemetry\": { \"speed\": 8.1, \"heading\": 98.7, \"battery\": 64.0, \"signal_strength\": 75.0 },\n",
    "  \"signature\": \"ed25519:98765fedcba...\",\n",
    "  \"firmware_version\": \"v2.0.0\",\n",
    "  \"operator_id\": \"OP-05\",\n",
    "  \"additional_metadata\": { \"camera_model\": \"CAM-PRO-4k\", \"mission_sensitivity\": \"critical\" }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b9c55",
   "metadata": {},
   "source": [
    "## 2. Sample outputs from the Ingestion Interceptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c4145",
   "metadata": {},
   "source": [
    "Ingest Output for Sample A (DRN-001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%JSON\n",
    "{\n",
    "  \"ingest_metadata\": {\n",
    "    \"ingest_id\": \"ingest_9f1a2b3c4d\",\n",
    "    \"drone_id\": \"DRN-001\",\n",
    "    \"timestamp\": \"2025-10-13T03:00:12Z\",\n",
    "    \"mission_id\": \"MSN-142\",\n",
    "    \"mission_zone\": \"zone-a\",\n",
    "    \"geo\": { \"lat\": 12.971598, \"lon\": 77.594566, \"alt\": 120 },\n",
    "    \"operator_id\": \"OP-12\",\n",
    "    \"firmware_version\": \"v1.2.0\",\n",
    "    \"num_files\": 2,\n",
    "    \"insecure_flags\": [],\n",
    "    \"auth_result\": \"ok\",\n",
    "    \"notes\": \"normal video+image feed\"\n",
    "  },\n",
    "  \"artifact_records\": [\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://a3f8e9b2c1d4\",\n",
    "      \"filename\": \"drn001_fpv_001.mp4\",\n",
    "      \"type\": \"video\",\n",
    "      \"mime\": \"video/mp4\",\n",
    "      \"size_bytes\": 4500000,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"thumbnail\": \"thumb://6d7a8b9c0d\",\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/a3f8e9b2c1d4\"\n",
    "    },\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://b4c5d6e7f8a9\",\n",
    "      \"filename\": \"drn001_cam_001.jpg\",\n",
    "      \"type\": \"image\",\n",
    "      \"mime\": \"image/jpeg\",\n",
    "      \"size_bytes\": 320000,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"thumbnail\": \"thumb://1a2b3c4d5e\",\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/b4c5d6e7f8a9\"\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e44e01",
   "metadata": {},
   "source": [
    "Ingest Output for Sample B (DRN-002 — encrypted nested archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a499cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%JSON\n",
    "{\n",
    "  \"ingest_metadata\": {\n",
    "    \"ingest_id\": \"ingest_c7d6e5f4a3\",\n",
    "    \"drone_id\": \"DRN-002\",\n",
    "    \"timestamp\": \"2025-10-13T03:05:45Z\",\n",
    "    \"mission_id\": \"MSN-143\",\n",
    "    \"mission_zone\": \"zone-c\",\n",
    "    \"geo\": { \"lat\": 13.035542, \"lon\": 77.597100, \"alt\": 85 },\n",
    "    \"operator_id\": \"OP-23\",\n",
    "    \"firmware_version\": \"v1.1.9\",\n",
    "    \"num_files\": 2,\n",
    "    \"insecure_flags\": [\"encrypted_payload\", \"nested_archive\"],\n",
    "    \"auth_result\": \"unknown\",\n",
    "    \"notes\": \"encrypted ZIP with nested contents — flag for deferred analysis\"\n",
    "  },\n",
    "  \"artifact_records\": [\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://c1d2e3f4a5b6\",\n",
    "      \"filename\": \"payload_bundle.zip\",\n",
    "      \"type\": \"archive\",\n",
    "      \"mime\": \"application/zip\",\n",
    "      \"size_bytes\": 4200000,\n",
    "      \"encryption\": true,\n",
    "      \"container\": true,\n",
    "      \"thumbnail\": null,\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/c1d2e3f4a5b6\"\n",
    "    },\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://d7e8f9a0b1c2\",\n",
    "      \"filename\": \"notes.txt\",\n",
    "      \"type\": \"text\",\n",
    "      \"mime\": \"text/plain\",\n",
    "      \"size_bytes\": 2048,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"thumbnail\": null,\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/d7e8f9a0b1c2\"\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d3698",
   "metadata": {},
   "source": [
    "Ingest Output for Sample C (DRN-003 — telemetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817b4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%JSON\n",
    "{\n",
    "  \"ingest_metadata\": {\n",
    "    \"ingest_id\": \"ingest_e8f7g6h5i4\",\n",
    "    \"drone_id\": \"DRN-003\",\n",
    "    \"timestamp\": \"2025-10-13T03:10:03Z\",\n",
    "    \"mission_id\": \"MSN-144\",\n",
    "    \"mission_zone\": \"zone-b\",\n",
    "    \"geo\": { \"lat\": 12.967800, \"lon\": 77.601200, \"alt\": 35 },\n",
    "    \"operator_id\": \"OP-33\",\n",
    "    \"firmware_version\": \"v1.2.3\",\n",
    "    \"num_files\": 1,\n",
    "    \"insecure_flags\": [],\n",
    "    \"auth_result\": \"ok\",\n",
    "    \"notes\": \"telemetry-only — low risk\"\n",
    "  },\n",
    "  \"artifact_records\": [\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://e9f0g1h2i3j4\",\n",
    "      \"filename\": \"telemetry_snapshot.json\",\n",
    "      \"type\": \"telemetry\",\n",
    "      \"mime\": \"application/json\",\n",
    "      \"size_bytes\": 1500,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"thumbnail\": null,\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/e9f0g1h2i3j4\"\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc3882e",
   "metadata": {},
   "source": [
    "Ingest Output for Sample D (DRN-004 — mission-critical large video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e937bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%JSON\n",
    "{\n",
    "  \"ingest_metadata\": {\n",
    "    \"ingest_id\": \"ingest_f1e2d3c4b5\",\n",
    "    \"drone_id\": \"DRN-004\",\n",
    "    \"timestamp\": \"2025-10-13T03:15:22Z\",\n",
    "    \"mission_id\": \"MSN-145\",\n",
    "    \"mission_zone\": \"zone-a\",\n",
    "    \"geo\": { \"lat\": 12.975000, \"lon\": 77.590000, \"alt\": 200 },\n",
    "    \"operator_id\": \"OP-05\",\n",
    "    \"firmware_version\": \"v2.0.0\",\n",
    "    \"num_files\": 2,\n",
    "    \"insecure_flags\": [],\n",
    "    \"auth_result\": \"ok\",\n",
    "    \"notes\": \"large survey video — mission sensitivity: critical\"\n",
    "  },\n",
    "  \"artifact_records\": [\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://f2e3d4c5b6a7\",\n",
    "      \"filename\": \"survey_coverage_long.mp4\",\n",
    "      \"type\": \"video\",\n",
    "      \"mime\": \"video/mp4\",\n",
    "      \"size_bytes\": 12500000,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"thumbnail\": \"thumb://abc123def456\",\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/f2e3d4c5b6a7\"\n",
    "    },\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://g3h4i5j6k7l8\",\n",
    "      \"filename\": \"survey_frame_2345.jpg\",\n",
    "      \"type\": \"image\",\n",
    "      \"mime\": \"image/jpeg\",\n",
    "      \"size_bytes\": 550000,\n",
    "      \"encryption\": false,\n",
    "      \"container\": false,\n",
    "      \"thumbnail\": \"thumb://789xyz456\",\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/g3h4i5j6k7l8\"\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284fd321",
   "metadata": {},
   "source": [
    "NOTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d15671",
   "metadata": {},
   "source": [
    "ingest_metadata.insecure_flags should be a short set of heuristics the Interceptor detects (e.g., \"encrypted_payload\", \"nested_archive\", \"unknown_signature\", \"large_binary\"). Use these to increase estimator priors.\n",
    "\n",
    "artifact_records.pointer_storage shows where the payload is stored for sandbox or forensics (S3/MinIO path). In this notebook we can mock this with artifact:// URIs.\n",
    "\n",
    "auth_result values: \"ok\", \"unknown\", \"failed\" — feed these as features into the Reputation/Estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef9830",
   "metadata": {},
   "source": [
    "## Game Theoretic Threat Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ef255",
   "metadata": {},
   "source": [
    "Here’s where the “game” happens:\n",
    "| Role                     | Player                   | Choices                                       | Examples |\n",
    "| ------------------------ | ------------------------ | --------------------------------------------- | -------- |\n",
    "| **Defender (System)**    | Chooses inspection depth | Signature, AI/ML, Sandbox                     |          |\n",
    "| **Attacker (Adversary)** | Chooses attack strength  | No attack, Simple malware, Obfuscated malware |          |\n",
    "\n",
    "\n",
    "The system predicts how smart or aggressive the attacker might be and chooses the most cost-effective defense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93576828",
   "metadata": {},
   "source": [
    "### The Logic Behind It\n",
    "\n",
    "Each defense has a cost (CPU time, latency).\n",
    "\n",
    "Each attack has a gain or loss depending on whether it succeeds or fails.\n",
    "\n",
    "The estimator simulates both sides, calculates possible outcomes, and decides the best defense level that minimizes overall risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae17def",
   "metadata": {},
   "source": [
    "### Game Mathematics in Simple Terms\n",
    "Each choice pair (Defender’s strategy, Attacker’s move) gives payoffs:\n",
    "|                | No Attack                       | Attack             |\n",
    "| -------------- | ------------------------------- | ------------------ |\n",
    "| Signature Scan | Low cost, low catch rate        | Cheap but risky    |\n",
    "| AI/ML Scan     | Moderate cost, better detection | Balance            |\n",
    "| Sandbox        | Expensive, strong catch         | High cost but safe |\n",
    "\n",
    "The system calculates:\n",
    "\n",
    "The defender’s utility (U_d) = benefit of detection – cost\n",
    "\n",
    "The attacker’s utility (U_a) = success of attack – effort/cost\n",
    "\n",
    "Then finds the Stackelberg equilibrium:\n",
    "    The defender’s best strategy knowing how the attacker will respond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b998e7",
   "metadata": {},
   "source": [
    "### Parameters That Influence the Game\n",
    "\n",
    "| Parameter  | Meaning                     | Example                                      |\n",
    "| ---------- | --------------------------- | -------------------------------------------- |\n",
    "| **R**      | Reputation of drone (trust) | Based on history, 0–1                        |\n",
    "| **Z**      | Zone risk                   | 0 = safe base, 1 = warzone                   |\n",
    "| **H**      | Past infection rate         | Higher → more suspicious                     |\n",
    "| **I_base** | Impact of file type         | Images = low, encrypted ZIPs = high          |\n",
    "| **C_d**    | Defender cost per strategy  | Sandbox costs more than signature            |\n",
    "| **DSR**    | Detection success rate      | How effective each layer is                  |\n",
    "| **T_S**    | Threat score                | Final 0–1 score derived from the equilibrium |\n",
    "\n",
    "\n",
    "NOTE: More parameters may be added in future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49647e3",
   "metadata": {},
   "source": [
    "### Outcome\n",
    "The estimator produces two outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%JSON\n",
    "{\n",
    "  \"Threat_Score\": 0.72,\n",
    "  \"Inspection_Level\": \"High\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38c179",
   "metadata": {},
   "source": [
    "- If T_S < 0.4, → Low (Signature only)\n",
    "\n",
    "- If 0.4 ≤ T_S < 0.7, → Medium (Signature + ML)\n",
    "\n",
    "- If T_S ≥ 0.7, → High (Sandbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfedf8ef",
   "metadata": {},
   "source": [
    "### Intuitive Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53f37c",
   "metadata": {},
   "source": [
    "| Drone ID | Reputation | Zone Risk | Past Infection | Threat Score | Decision        |\n",
    "| -------- | ---------- | --------- | -------------- | ------------ | --------------- |\n",
    "| DRN-001  | 0.9        | 0.2       | 0.0            | 0.25         | Low (Signature) |\n",
    "| DRN-007  | 0.6        | 0.7       | 0.3            | 0.65         | Medium (ML)     |\n",
    "| DRN-013  | 0.3        | 0.8       | 0.6            | 0.85         | High (Sandbox)  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfea734",
   "metadata": {},
   "source": [
    "### Step 1 — Variables, Inputs & Assumptions\n",
    "\n",
    "These are the variables and parameters required by the estimator for each incoming artifact. \n",
    "\n",
    "#### Core Inputs from the Ingestion Interceptor\n",
    "\n",
    "- **drone_id** — *string*. Unique ID for the sending drone.\n",
    "- **timestamp** — *ISO8601 string*. When the feed was captured.\n",
    "- **mission_zone** — *string*. Named area or zone id (used to look up zone risk).\n",
    "- **geo** — *object* `{lat, lon, alt}`. (optional for now)\n",
    "- **artifact_records** — *list of artifacts* (each with: filename, type, mime, size_bytes, encryption, container, checksum, thumbnail, pointer_storage).\n",
    "\n",
    "#### Derived / System Inputs (lookup or compute at estimator)\n",
    "\n",
    "- **R** — *reputation* of the drone/source, numeric in [0, 1].  \n",
    "    - 1 = fully trusted, 0 = fully untrusted.  \n",
    "    - Default: 0.8 for new devices.  \n",
    "    - Source: reputation DB (Redis/Postgres) updated by Feedback Loop.\n",
    "\n",
    "- **Z** — *zone risk*, numeric in [0, 1].  \n",
    "    - 0 = safe zone, 1 = highest-risk (e.g., conflict area).  \n",
    "    - Default: 0.5 (neutral) if unknown.  \n",
    "    - Source: static policy table or dynamic intelligence.\n",
    "\n",
    "- **H** — *recent infection frequency* for this drone (or zone), numeric in [0, 1].  \n",
    "    - Fraction of recent feeds confirmed malicious.  \n",
    "    - Default: 0.0 if no historic detections.  \n",
    "    - Example: 0.2 means 20% of last N feeds were malicious.\n",
    "\n",
    "- **TI_boost** — *threat-intel corroboration strength*, numeric in [0, 1].  \n",
    "    - 0 if no IOC matches; >0 if indicators match known bad IOCs (higher = stronger corroboration).  \n",
    "    - Default: 0.0.\n",
    "\n",
    "- **I_base** — *base impact* of the artifact (0..10).  \n",
    "    - How bad it would be if this artifact were malicious (mission-criticality + file-type).  \n",
    "    - Example mapping (starter heuristic):  \n",
    "        - telemetry / small text → 1–2  \n",
    "        - images → 3–6  \n",
    "        - video / large survey → 6–9  \n",
    "        - encrypted archive with docs → 8–10  \n",
    "    - Default: compute from artifact_records.\n",
    "\n",
    "#### Defender / Attacker Model Constants (tunable)\n",
    "\n",
    "- **DSR(s)** — base detection success rate per defender strategy s (value in (0,1)).  \n",
    "    - Defaults:  \n",
    "        - DSR('signature') = 0.70  \n",
    "        - DSR('ml') = 0.85  \n",
    "        - DSR('sandbox') = 0.95\n",
    "\n",
    "- **C_d(s)** — defender cost for strategy s (abstract units).  \n",
    "    - Defaults:  \n",
    "        - C_d('signature') = 1.0  \n",
    "        - C_d('ml') = 3.0  \n",
    "        - C_d('sandbox') = 6.0\n",
    "\n",
    "- **C_a(a)** — attacker cost for action a.  \n",
    "    - Defaults:  \n",
    "        - C_a('inject') = 2.0  \n",
    "        - C_a('no_inject') = 0.0\n",
    "\n",
    "#### Tunable Weights and Small Constants\n",
    "\n",
    "- **alpha (α)** — reputation influence on impact (α = 0.5 default).\n",
    "- **beta (β)** — zone risk influence on impact (β = 0.3 default).\n",
    "- **gamma (γ)** — history effect on detection (γ = 0.2 default).\n",
    "- **delta (δ)** — TI boost effect on detection (δ = 0.0 default).\n",
    "- **kappa (κ)** — sigmoid scale for raw → normalized mapping (κ = 0.8 default).\n",
    "- **lambda_blend (λ)** — weight blending model score with reputation (λ = 0.9 default).\n",
    "- **eps** — clamp epsilon to avoid exact 0 or 1 in probabilities (e.g., eps = 0.001).\n",
    "\n",
    "#### Thresholds — Inspection Mapping\n",
    "\n",
    "- **th_low = 0.4**\n",
    "- **th_high = 0.7**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178dbb7",
   "metadata": {},
   "source": [
    "# Step 2 — Compute adjusted parameters (`I_prime`, `DSR_prime(s)`)\n",
    "\n",
    "We’ll compute the two things the estimator needs before building payoff matrices:\n",
    "\n",
    "1. **Adjusted impact** ($I'$) — how bad it is if this artifact is malicious, after accounting for reputation + zone risk.\n",
    "2. **Adjusted detection success rates** ($\\mathrm{DSR}'(s)$) — how likely each defense is to catch malware given history and TI.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Formula: Adjusted impact ($I'$)\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "I' = I_{\\text{base}} \\, (1 + \\alpha (1 - R)) \\, (1 + \\beta Z)\n",
    "$$\n",
    "\n",
    "**Terms explained**\n",
    "\n",
    "* $I_{\\text{base}}$: base impact (0–10), derived from file type / mission sensitivity.\n",
    "* $R$ (0–1): reputation (1 = trusted). The factor $(1-R)$ increases impact if reputation is low.\n",
    "* $\\alpha$: how strongly reputation affects impact (default **0.5**).\n",
    "* $Z$ (0–1): zone risk.\n",
    "* $\\beta$: how strongly zone risk affects impact (default **0.3**).\n",
    "\n",
    "**Why multiplicative?**\n",
    "* Multiplying keeps effects proportional — a high base impact in a risky zone with low reputation becomes substantially larger.\n",
    "\n",
    "**Defaults**\n",
    "\n",
    "* $\\alpha = 0.5,\\ \\beta = 0.3$\n",
    "\n",
    "**Heuristic for $I_{\\text{base}}$ (practical)**\n",
    "\n",
    "Estimate from artifact types and sizes:\n",
    "\n",
    "| Type | Typical $I_{\\text{base}}$ |\n",
    "|------|-----------------------------|\n",
    "| telemetry / small text | 1–2 |\n",
    "| image | 3–6 |\n",
    "| video / survey | 6–9 |\n",
    "| encrypted archive / executable | 8–10 |\n",
    "\n",
    "Example heuristic formula:\n",
    "\n",
    "$$\n",
    "I_{\\text{base}} = \\mathrm{clip}\\big(3 + 3 \\cdot (\\text{avg\\_size\\_MB}) + 3 \\cdot \\text{type\\_risk},\\ 0, 10\\big)\n",
    "$$\n",
    "\n",
    "where `type_risk` = 0.2 / 0.7 / 0.9 for low / archive / video, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### Worked numeric example\n",
    "\n",
    "Given:\n",
    "* $I_{\\text{base}} = 8$ (sensitive archive)\n",
    "* $R = 0.4$\n",
    "* $Z = 0.6$\n",
    "* $\\alpha = 0.5$\n",
    "* $\\beta = 0.3$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "I' &= 8 \\cdot (1 + 0.5 \\cdot (1-0.4)) \\cdot (1 + 0.3 \\cdot 0.6) \\\\\n",
    "&= 8 \\cdot (1 + 0.3) \\cdot (1 + 0.18) \\\\\n",
    "&= 8 \\cdot 1.3 \\cdot 1.18 \\approx 12.272\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So the effective impact increases from 8 → ~12.27.  \n",
    "(Values >10 are fine internally; we can clamp later.)\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 Formula: Adjusted detection success rate ($\\mathrm{DSR}'(s)$)\n",
    "\n",
    "**Formula**\n",
    "\n",
    "$$\n",
    "\\mathrm{DSR}'(s) = \\mathrm{clamp}\\Big( \\mathrm{DSR}(s) \\cdot (1 - \\gamma H) \\cdot (1 + \\delta \\, \\mathrm{TI}),\\ \\varepsilon,\\ 1 - \\varepsilon \\Big)\n",
    "$$\n",
    "\n",
    "where `clamp(x, a, b) = max(a, min(b, x))`.\n",
    "\n",
    "---\n",
    "\n",
    "**Terms explained**\n",
    "\n",
    "* $\\mathrm{DSR}(s)$: base detection success rate for strategy $s$ (signature / ml / sandbox).  \n",
    "  Defaults: signature=0.70, ml=0.85, sandbox=0.95.\n",
    "* $H$ (0–1): recent infection frequency (history). Multiplies by $(1 - \\gamma H)$ to *reduce* DSR when evasion occurs.\n",
    "* $\\gamma$: strength of history effect (default **0.2**).\n",
    "* $\\mathrm{TI}$ (0–1): threat-intel corroboration strength.\n",
    "* $\\delta$: TI multiplier (default **0.0** until TI available).\n",
    "* $\\varepsilon$: clamp epsilon (default **0.001**) — avoids exact 0 or 1.\n",
    "\n",
    "---\n",
    "\n",
    "**Why multiplicative?**\n",
    "\n",
    "History degrades success *proportionally* (e.g., 90% → 80%).  \n",
    "TI slightly boosts DSR when relevant.\n",
    "\n",
    "---\n",
    "\n",
    "**Worked numeric example**\n",
    "\n",
    "Given:\n",
    "* $\\mathrm{DSR}(\\text{signature}) = 0.70$\n",
    "* $H = 0.2$\n",
    "* $\\gamma = 0.2$\n",
    "* $\\mathrm{TI} = 0$\n",
    "* $\\delta = 0$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{DSR}'(\\text{signature}) &= 0.70 \\cdot (1 - 0.2 \\cdot 0.2) \\\\\n",
    "&= 0.70 \\cdot (1 - 0.04) = 0.70 \\cdot 0.96 = 0.672\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Attacker success probability vs signature:\n",
    "\n",
    "$$\n",
    "\\mathrm{ASP} = 1 - 0.672 = 0.328\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Edge cases**\n",
    "* If $H = 0$, then $\\mathrm{DSR}' = \\mathrm{DSR}$.\n",
    "* If TI strong and $\\delta>0$, DSR increases.\n",
    "* Always clamp to $[\\varepsilon, 1 - \\varepsilon]$.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.3 Small Python snippet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bf286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: compute I_prime and DSR_prime(s)\n",
    "def clamp(x, a=1e-3, b=1-1e-3):\n",
    "    return max(a, min(b, x))\n",
    "\n",
    "# defaults (tune later)\n",
    "alpha, beta, gamma, delta = 0.5, 0.3, 0.2, 0.0\n",
    "eps = 1e-3\n",
    "DSR_base = {'signature': 0.70, 'ml': 0.85, 'sandbox': 0.95}\n",
    "\n",
    "def compute_I_prime(I_base, R, Z, alpha=alpha, beta=beta):\n",
    "    return I_base * (1 + alpha * (1 - R)) * (1 + beta * Z)\n",
    "\n",
    "def compute_DSR_primes(DSR_base, H, TI=0.0, gamma=gamma, delta=delta, eps=eps):\n",
    "    DSR_prime = {}\n",
    "    for s, base in DSR_base.items():\n",
    "        val = base * (1 - gamma * H) * (1 + delta * TI)\n",
    "        DSR_prime[s] = clamp(val, eps, 1 - eps)\n",
    "    return DSR_prime\n",
    "\n",
    "# Example values\n",
    "I_base = 8.0   # sensitive archive\n",
    "R = 0.4\n",
    "Z = 0.6\n",
    "H = 0.2\n",
    "TI = 0.0\n",
    "\n",
    "I_prime = compute_I_prime(I_base, R, Z)\n",
    "DSR_prime = compute_DSR_primes(DSR_base, H, TI)\n",
    "\n",
    "print(\"I_prime =\", round(I_prime, 6))\n",
    "print(\"DSR_prime =\", {k: round(v, 6) for k, v in DSR_prime.items()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12404d25",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "source": [
    "Running the snippet yields:\n",
    "\n",
    "* `I_prime ≈ 12.272`\n",
    "* `DSR_prime`: signature ≈ 0.672, ml ≈ 0.833, sandbox ≈ 0.938\n",
    "\n",
    "---\n",
    "\n",
    "## 2.4 Quick checklist\n",
    "\n",
    "* Input: `I_base`, `R`, `Z`, `H`, `TI`, and `DSR_base`\n",
    "* Compute `I_prime` using formula above.\n",
    "* Compute `DSR_prime` for each defender strategy and clamp.\n",
    "* Store results for later payoff matrix construction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19613c40",
   "metadata": {},
   "source": [
    "# Step 3 — Payoff matrices & utilities ($U_d$ and $U_a$)\n",
    "\n",
    "---\n",
    "\n",
    "## 3.0 Recap of inputs we already have\n",
    "\n",
    "From previous steps we have:\n",
    "\n",
    "* $I'$ — adjusted impact (scalar)\n",
    "* $\\mathrm{DSR}'(s)$ — map of adjusted detection success rates\n",
    "* $C_d[s]$ — defender cost per strategy\n",
    "* $C_a[a]$ — attacker cost per action\n",
    "* Defender strategies $S_d = [\\text{signature}, \\text{ml}, \\text{sandbox}]$\n",
    "* Attacker actions $S_a = [\\text{inject}, \\text{no\\_inject}]$\n",
    "\n",
    "We will use these to build two matrices:\n",
    "\n",
    "* $U_d[i][j]$ = defender payoff when defender picks strategy *i* and attacker picks action *j*\n",
    "* $U_a[i][j]$ = attacker payoff for the same cell\n",
    "\n",
    "Rows = defender strategies, columns = attacker actions.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Payoff formulas (final and conservative)\n",
    "\n",
    "### Defender payoff\n",
    "\n",
    "$$\n",
    "U_d(s,a)=\n",
    "\\begin{cases}\n",
    "\\mathrm{DSR}'(s)\\,I' - C_d(s), & a=\\text{inject} \\\\\\\\[4pt]\n",
    "-\\,C_d(s), & a=\\text{no\\_inject}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "* If the attacker injects, defender gains expected prevented impact minus inspection cost.  \n",
    "* If the attacker doesn’t inject, defender only pays inspection cost — discouraging unnecessary deep inspection.\n",
    "\n",
    "---\n",
    "\n",
    "### Attacker payoff\n",
    "\n",
    "$$\n",
    "U_a(s,a)=\n",
    "\\begin{cases}\n",
    "(1-\\mathrm{DSR}'(s))\\,I' - C_a(a), & a=\\text{inject} \\\\\\\\[4pt]\n",
    "0, & a=\\text{no\\_inject}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "Expected successful impact (ASP × $I′$) minus attack cost.  \n",
    "If attacker doesn’t inject → no impact, no cost, payoff = 0.\n",
    "\n",
    "---\n",
    "## 3.2 Matrix layout (example structure)\n",
    "\n",
    "For  \n",
    "$S_d = [\\text{signature}, \\text{ml}, \\text{sandbox}]$  \n",
    "and  \n",
    "$S_a = [\\text{inject}, \\text{no\\_inject}]$:\n",
    "\n",
    "**$U_a$ (attacker)**\n",
    "\n",
    "| $S_d \\setminus S_a$ | inject | no\\_inject |\n",
    "| :--- | :--- | :--- |\n",
    "| **signature** | $U_a(\\text{sig},\\text{inject})$ | $U_a(\\text{sig},\\text{no\\_inject})$ |\n",
    "| **ml** | $U_a(\\text{ml},\\text{inject})$ | $U_a(\\text{ml},\\text{no\\_inject})$ |\n",
    "| **sandbox** | $U_a(\\text{sbx},\\text{inject})$ | $U_a(\\text{sbx},\\text{no\\_inject})$ |\n",
    "\n",
    "<hr>\n",
    "\n",
    "**$U_d$ (defender)**\n",
    "\n",
    "| $S_d \\setminus S_a$ | inject | no\\_inject |\n",
    "| :--- | :--- | :--- |\n",
    "| **signature** | $U_d(\\text{sig},\\text{inject})$ | $U_d(\\text{sig},\\text{no\\_inject})$ |\n",
    "| **ml** | $U_d(\\text{ml},\\text{inject})$ | $U_d(\\text{ml},\\text{no\\_inject})$ |\n",
    "| **sandbox** | $U_d(\\text{sbx},\\text{inject})$ | $U_d(\\text{sbx},\\text{no\\_inject})$ |\n",
    "\n",
    "We’ll compute both and log them for audit.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.3 Decision logic (Stackelberg pure-strategy enumerator)\n",
    "\n",
    "We use **defender-as-leader** logic:\n",
    "\n",
    "1. For each defender strategy $s$:  \n",
    "   * Attacker chooses best response $a^* = \\arg\\max_a U_a(s,a)$  \n",
    "   * Defender’s resulting payoff $V_d(s) = U_d(s,a^*)$\n",
    "2. Defender picks $s^* = \\arg\\max_s V_d(s)$\n",
    "3. Equilibrium cell $(s^*, a^*)$ has  \n",
    "   $U_{d,\\mathrm{eq}} = U_d(s^*,a^*)$, $U_{a,\\mathrm{eq}} = U_a(s^*,a^*)$\n",
    "\n",
    "Ties: attacker prefers worse for defender; defender prefers cheaper among equals.  \n",
    "Complexity = $\\mathcal{O}(|S_d|\\times|S_a|)$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.4 Numeric worked example\n",
    "\n",
    "Inputs:\n",
    "\n",
    "* $I' = 12.272$\n",
    "* $\\mathrm{DSR}' = \\{\\text{signature}:0.672,\\ \\text{ml}:0.833,\\ \\text{sandbox}:0.938\\}$\n",
    "* $C_d = \\{\\text{signature}:1.0,\\ \\text{ml}:3.0,\\ \\text{sandbox}:6.0\\}$\n",
    "* $C_a = \\{\\text{inject}:2.0,\\ \\text{no\\_inject}:0.0\\}$\n",
    "\n",
    "Compute attacker success probabilities:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{ASP}(\\text{sig}) &= 1 - 0.672 = 0.328 \\\\\n",
    "\\mathrm{ASP}(\\text{ml}) &= 1 - 0.833 = 0.167 \\\\\n",
    "\\mathrm{ASP}(\\text{sbx}) &= 1 - 0.938 = 0.062\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Attacker payoffs\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "U_a(\\text{sig},\\text{inject}) &= 0.328\\times12.272 - 2 = 2.024 \\\\\n",
    "U_a(\\text{ml},\\text{inject}) &= 0.167\\times12.272 - 2 = 0.049 \\\\\n",
    "U_a(\\text{sbx},\\text{inject}) &= 0.062\\times12.272 - 2 = -1.240\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "All $U_a(\\cdot,\\text{no\\_inject})=0$\n",
    "\n",
    "\\[\n",
    "U_a=\n",
    "\\begin{bmatrix}\n",
    "2.024 & 0\\\\\n",
    "0.049 & 0\\\\\n",
    "-1.24 & 0\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### Defender payoffs (conservative model)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "U_d(\\text{sig},\\text{inject}) &= 0.672\\times12.272 - 1 = 7.251 \\\\\n",
    "U_d(\\text{sig},\\text{no\\_inject}) &= -1 \\\\\n",
    "U_d(\\text{ml},\\text{inject}) &= 0.833\\times12.272 - 3 = 7.218 \\\\\n",
    "U_d(\\text{ml},\\text{no\\_inject}) &= -3 \\\\\n",
    "U_d(\\text{sbx},\\text{inject}) &= 0.938\\times12.272 - 6 = 5.510 \\\\\n",
    "U_d(\\text{sbx},\\text{no\\_inject}) &= -6\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\\[\n",
    "U_d=\n",
    "\\begin{bmatrix}\n",
    "7.251 & -1\\\\\n",
    "7.218 & -3\\\\\n",
    "5.510 & -6\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "### Attacker best responses\n",
    "\n",
    "| Defender s | Best attacker a | Reason |\n",
    "|-------------|----------------|--------|\n",
    "| signature | inject | 2.024 > 0 |\n",
    "| ml | inject | 0.049 > 0 |\n",
    "| sandbox | no_inject | 0 > −1.24 |\n",
    "\n",
    "Defender payoffs when attacker best-responds:\n",
    "\n",
    "| s | $V_d(s)$ |\n",
    "|---|------------|\n",
    "| signature | 7.251 |\n",
    "| ml | 7.218 |\n",
    "| sandbox | −6.000 |\n",
    "\n",
    "Defender picks **signature** (highest 7.251).  \n",
    "Equilibrium: $(\\text{signature},\\text{inject})$  \n",
    "Utilities: $U_{d,\\mathrm{eq}}=7.251$, $U_{a,\\mathrm{eq}}=2.024$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3.5 Python snippet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae08688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build payoff matrices and solve pure-strategy Stackelberg (conservative model)\n",
    "def build_payoff_matrices(I_prime, DSR_prime, C_d, C_a, defender_strats, attacker_actions):\n",
    "    U_a = []  # attacker payoff rows\n",
    "    U_d = []  # defender payoff rows\n",
    "    for s in defender_strats:\n",
    "        row_a = []\n",
    "        row_d = []\n",
    "        dsr = DSR_prime[s]\n",
    "        asp = 1.0 - dsr\n",
    "        for a in attacker_actions:\n",
    "            ua = asp * I_prime - C_a[a]\n",
    "            ud = (dsr * I_prime - C_d[s]) if a == 'inject' else (-C_d[s])\n",
    "            row_a.append(round(ua,6))\n",
    "            row_d.append(round(ud,6))\n",
    "        U_a.append(row_a)\n",
    "        U_d.append(row_d)\n",
    "    return U_a, U_d\n",
    "\n",
    "def solve_stackelberg_pure(U_a, U_d, defender_strats, attacker_actions):\n",
    "    best_def = None\n",
    "    for i, row in enumerate(U_a):\n",
    "        j_best = max(range(len(row)), key=lambda j: row[j])\n",
    "        ua = row[j_best]\n",
    "        ud = U_d[i][j_best]\n",
    "        if best_def is None or ud > best_def['ud']:\n",
    "            best_def = {'ud': ud, 'ua': ua, 'di': i, 'aj': j_best}\n",
    "    return {\n",
    "        'defender_index': best_def['di'],\n",
    "        'attacker_index': best_def['aj'],\n",
    "        'defender_strategy': defender_strats[best_def['di']],\n",
    "        'attacker_action': attacker_actions[best_def['aj']],\n",
    "        'U_d_eq': best_def['ud'],\n",
    "        'U_a_eq': best_def['ua']\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "I_prime = 12.272\n",
    "DSR_prime = {'signature':0.672, 'ml':0.833, 'sandbox':0.938}\n",
    "C_d = {'signature':1.0,'ml':3.0,'sandbox':6.0}\n",
    "C_a = {'inject':2.0, 'no_inject':0.0}\n",
    "defender_strats = ['signature','ml','sandbox']\n",
    "attacker_actions = ['inject','no_inject']\n",
    "\n",
    "U_a, U_d = build_payoff_matrices(I_prime, DSR_prime, C_d, C_a, defender_strats, attacker_actions)\n",
    "print(\"U_a (attacker payoff matrix):\")\n",
    "print(U_a)\n",
    "print(\"U_d (defender payoff matrix):\")\n",
    "print(U_d)\n",
    "\n",
    "eq = solve_stackelberg_pure(U_a, U_d, defender_strats, attacker_actions)\n",
    "print(\"\\nEquilibrium:\")\n",
    "print(eq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf7be0",
   "metadata": {},
   "source": [
    "## 3.6 Notes, choices, and caveats\n",
    "\n",
    "* **Interpretation:** discourages over-inspection when threat is low.\n",
    "* **Attacker action granularity:** can extend with `obfuscated_inject`, etc.\n",
    "* **Tie-breaking:** attacker prefers worse outcome for defender; defender prefers cheaper among equals.\n",
    "* **Logging:** record all computed matrices (`U_a`, `U_d`), inputs, and equilibrium for audit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce616f8",
   "metadata": {},
   "source": [
    "# Step 4 — From equilibrium utilities to **Threat Score ($\\mathbf{T_S}$)** and **Inspection Level**\n",
    "\n",
    "We now convert the equilibrium utilities we computed in Step 3 into a single, bounded **Threat Score** and an actionable **inspection level**. \n",
    "We'll do this step-by-step: raw metric, normalization (sigmoid), blend with reputation, thresholds $\\rightarrow$ inspection level, worked numeric example, code we can paste into our notebook, and short notes on calibration and logging.\n",
    "\n",
    "***\n",
    "\n",
    "## 4.1 Why this mapping and goals\n",
    "\n",
    "* Raw utilities (`U_a_eq`, `U_d_eq`) are in abstract units and can be negative/large; we need a compact value in **[0,1]** to route decisions and monitor. \n",
    "* The mapping must reflect *attacker advantage*: if attacker utility $\\gg$ defender utility, threat should be high. \n",
    "* We also want to incorporate **reputation** so known-good sources stay lower-risk even if raw favors attacker slightly.\n",
    "\n",
    "***\n",
    "\n",
    "## 4.2 Step A — Raw metric\n",
    "\n",
    "Compute the attacker advantage (raw):\n",
    "\n",
    "$$\\text{raw} = U_a^{eq} - U_d^{eq}$$\n",
    "\n",
    "* If `raw` is **positive**, attacker is ahead $\\rightarrow$ worry more. \n",
    "* If `raw` is **negative**, defender is ahead $\\rightarrow$ less worry.\n",
    "\n",
    "***\n",
    "\n",
    "## 4.3 Step B — Sigmoid normalization\n",
    "\n",
    "Map `raw` to a 0–1 value using a sigmoid function to get a smooth probability-like number:\n",
    "\n",
    "$$T_{\\text{raw}} = \\sigma(\\kappa \\cdot \\text{raw}) = \\frac{1}{1 + e^{-\\kappa \\cdot \\text{raw}}}$$\n",
    "\n",
    "* $\\mathbf{\\kappa}$ (kappa) scales sensitivity. Default: **0.8**.\n",
    "\n",
    "* Larger $\\mathbf{\\kappa}$ makes the sigmoid steeper (small raw differences produce stronger $T_{\\text{raw}}$ changes). \n",
    "* Smaller $\\mathbf{\\kappa}$ smooths differences.\n",
    "\n",
    "Properties:\n",
    "\n",
    "* $\\text{raw} \\to -\\infty \\Rightarrow T_{\\text{raw}} \\to 0$ \n",
    "* $\\text{raw} = 0 \\Rightarrow T_{\\text{raw}} = 0.5$ \n",
    "* $\\text{raw} \\to +\\infty \\Rightarrow T_{\\text{raw}} \\to 1$\n",
    "\n",
    "***\n",
    "\n",
    "## 4.4 Step C — Blend with reputation prior\n",
    "\n",
    "Blend the model signal with the reputation prior so that trusted sources are penalized less:\n",
    "\n",
    "$$T_S = \\lambda \\cdot T_{\\text{raw}} + (1 - \\lambda) \\cdot (1 - R)$$\n",
    "\n",
    "* $\\mathbf{\\lambda} \\in [0,1]$, defaults to **0.9** (90% model-driven, 10% reputation prior). \n",
    "* $1 - R$ gives higher baseline risk for low-reputation sources.\n",
    "\n",
    "Clamp to $[0,1]$:\n",
    "\n",
    "$$T_S \\leftarrow \\mathrm{clip}(T_S, 0, 1)$$\n",
    "\n",
    "Interpretation: $T_S$ is our final threat probability-like score.\n",
    "\n",
    "***\n",
    "\n",
    "## 4.5 Step D — Map $T_S$ to inspection level\n",
    "\n",
    "Use thresholds to select inspection depth:\n",
    "\n",
    "Default thresholds:\n",
    "\n",
    "* Low: $T_S < 0.4$ $\\rightarrow$ **Signature only** * Medium: $0.4 \\le T_S < 0.7$ $\\rightarrow$ **Signature + ML** * High: $T_S \\ge 0.7$ $\\rightarrow$ **Signature + ML + Sandbox**\n",
    "\n",
    "(we can change thresholds after calibration.)\n",
    "\n",
    "***\n",
    "\n",
    "## 4.6 Worked numeric example (continues previous example)\n",
    "\n",
    "From Step 3 equilibrium we had:\n",
    "\n",
    "$$U_a^{eq} = 2.024, \\quad U_d^{eq} = 7.251$$\n",
    "\n",
    "Compute raw:\n",
    "\n",
    "$$\\text{raw} = 2.024 - 7.251 = -5.227$$\n",
    "\n",
    "Sigmoid:\n",
    "\n",
    "$$T_{\\text{raw}} = \\sigma(\\kappa \\cdot \\text{raw}) = \\sigma(0.8 \\times -5.227) = \\sigma(-4.1816) \\approx 0.0147$$\n",
    "\n",
    "Blend with reputation (example $\\mathbf{R = 0.4, \\lambda = 0.9}$):\n",
    "\n",
    "$$T_S = 0.9 \\times 0.0147 + 0.1 \\times (1 - 0.4) = 0.01323 + 0.06 = 0.07323$$\n",
    "\n",
    "Clamp: still $0.0732$.\n",
    "\n",
    "Inspection level: $T_S < 0.4 \\Rightarrow \\text{Low (signature only)}$.\n",
    "\n",
    "**Interpretation:** equilibrium strongly favors defender, so threat is low.\n",
    "\n",
    "***\n",
    "\n",
    "## 4.7 Python snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc81f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# ---- parameters (tuneable) ----\n",
    "kappa = 0.8          # sigmoid scale\n",
    "lambda_blend = 0.9   # blend with reputation (model weight)\n",
    "th_low = 0.4\n",
    "th_high = 0.7\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def compute_threat_score(U_a_eq, U_d_eq, R, kappa=kappa, lambda_blend=lambda_blend):\n",
    "    raw = U_a_eq - U_d_eq\n",
    "    T_raw = sigmoid(kappa * raw)\n",
    "    T_S = lambda_blend * T_raw + (1.0 - lambda_blend) * (1.0 - R)\n",
    "    # clamp to [0,1]\n",
    "    T_S = max(0.0, min(1.0, T_S))\n",
    "    return {\n",
    "        \"raw\": round(raw,6),\n",
    "        \"T_raw\": round(T_raw,6),\n",
    "        \"T_S\": round(T_S,6)\n",
    "    }\n",
    "\n",
    "def map_inspection_level(T_S, th_low=th_low, th_high=th_high):\n",
    "    if T_S < th_low:\n",
    "        return \"Low\"\n",
    "    elif T_S < th_high:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "# Example use (values from earlier):\n",
    "U_a_eq = 2.024\n",
    "U_d_eq = 7.251\n",
    "R = 0.4\n",
    "\n",
    "score = compute_threat_score(U_a_eq, U_d_eq, R)\n",
    "level = map_inspection_level(score[\"T_S\"])\n",
    "print(\"score:\", score)\n",
    "print(\"inspection level:\", level)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ee3ca",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 4.8 Calibration notes (practical)\n",
    "\n",
    "1. **Pick $\\mathbf{\\kappa}$** by matching scale of raw: Inspect historical $\\text{raw}$ distribution; choose $\\kappa$ so typical raw values map to a good spread of $T_{\\text{raw}}$ in $(0.05..0.95)$. \n",
    "2. **Pick $\\mathbf{\\lambda}$** based on trust in our models vs reputation: If our historical labels are sparse, favor reputation more (lower $\\lambda$). If models are well-calibrated, set $\\lambda$ high. \n",
    "3. **Choose thresholds by cost tradeoff:**\n",
    "\n",
    "    * Measure: sandbox cost per artifact vs. cost of a missed infection. \n",
    "    * Choose $\\text{th\\_low}/\\text{th\\_high}$ to keep sandbox rate under capacity while meeting detection goals.\n",
    "4. **Validate:** compute ROC/AUC of $T_S$ vs ground truth (sandbox-confirmed) on historical dataset; tune $\\kappa$, $\\lambda$, thresholds to maximize operational utility.\n",
    "\n",
    "***\n",
    "\n",
    "## 4.9 Logging & observability (must-have)\n",
    "\n",
    "Log for each decision:\n",
    "\n",
    "* `I_prime`, `DSR_prime`, $U_a$ matrix, $U_d$ matrix, $U_a^{eq}$, $U_d^{eq}$, $\\text{raw}$, $T_{\\text{raw}}$, $T_S$, `inspection_level`, `model_version`, parameters ($\\kappa$, $\\lambda$, thresholds), `ingest_id`, `drone_id`. \n",
    "* This allows:\n",
    "    * forensic replay (why did we sandbox that file?), \n",
    "    * offline calibration and audits, \n",
    "    * measuring $T_S$ buckets vs actual confirmations.\n",
    "\n",
    "***\n",
    "\n",
    "## 4.10 Quick checklist for the notebook\n",
    "\n",
    "* Compute $U_a^{eq}$ and $U_d^{eq}$ (Step 3 results). \n",
    "* Call `compute_threat_score(U_a_eq, U_d_eq, R)` to get $T_S$. \n",
    "* Map to inspection level with `map_inspection_level`. \n",
    "* Log results and forward artifact pointer with inspection instruction to Detection Engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e401c44f",
   "metadata": {},
   "source": [
    "# Step 5 — Full pipeline implementation (runnable code)\n",
    "\n",
    "This step ties together **Steps 1–4** into a single executable estimator cell. \n",
    "The pipeline computes:\n",
    "\n",
    "$$\\text{ingest metadata} \\;\\Rightarrow\\; I_{\\text{base}},\\ I' \\;\\Rightarrow\\; \\mathrm{DSR}' \\;\\Rightarrow\\; U_a, U_d \n",
    "\\;\\Rightarrow\\; (U_a^{eq}, U_d^{eq}) \\;\\Rightarrow\\; T_S,\\ \\text{inspection level}.$$\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "## 5.1 Modeling choices recap\n",
    "\n",
    "* We use the **conservative** payoff for $\\text{no\\_inject}$:\n",
    "$$U_d(s,\\text{no\\_inject}) = -C_d(s)$$\n",
    "(no reward when no attack occurs; only inspection cost).\n",
    "* Parameters to tune: $\\alpha,\\beta,\\gamma,\\delta,\\kappa,\\lambda$ and thresholds.\n",
    "* Logging outputs: store $I_{\\text{base}}$, $I'$, $\\mathrm{DSR}'$, $U_a$, $U_d$, equilibrium, $T_S$, $\\text{inspection\\_level}$, and params for audit & calibration.\n",
    "\n",
    "***\n",
    "\n",
    "## 5.2 Where outputs are saved\n",
    "\n",
    "* In my run I saved results to `/mnt/data/estimator_full.json`. \n",
    "* The cell below is self-contained and will let we run the full estimator on ingest records.\n",
    "\n",
    "***\n",
    "\n",
    "## 5.3 Notes\n",
    "\n",
    "* Calibrate $\\mathrm{DSR}_{\\text{base}}$ and costs ($C_d$, $C_a$) with offline benchmarks. \n",
    "* Tune $\\kappa$ to match the scale of $\\text{raw} = U_a^{eq} - U_d^{eq}$ in the dataset. \n",
    "* Adjust $\\lambda$ to match the scale of $\\text{raw} = U_a^{eq} - U_d^{eq}$ in the dataset. \n",
    "* Adjust $\\lambda_{\\text{blend}}$ if reputation should have more/less weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Threat Estimator (copy-paste into Jupyter)\n",
    "import json, math, datetime, random\n",
    "\n",
    "# CONFIG (defaults - tune as needed)\n",
    "alpha=0.5; beta=0.3; gamma=0.2; delta=0.0; eps=1e-3\n",
    "kappa=0.8; lambda_blend=0.9; th_low=0.4; th_high=0.7\n",
    "DSR_base = {'signature':0.70,'ml':0.85,'sandbox':0.95}\n",
    "C_d = {'signature':1.0,'ml':3.0,'sandbox':6.0}\n",
    "C_a = {'inject':2.0,'no_inject':0.0}\n",
    "defender_strats = ['signature','ml','sandbox']\n",
    "attacker_actions = ['inject','no_inject']\n",
    "type_risk_map = {'telemetry':0.1,'text':0.2,'image':0.5,'video':0.9,'archive':0.8}\n",
    "\n",
    "def clamp(x,a=1e-3,b=1-1e-3): return max(a, min(b, x))\n",
    "def sigmoid(x): return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def compute_I_base(artifact_records, ingest_metadata):\n",
    "    sizes = [a.get('size_bytes',0) for a in artifact_records]\n",
    "    avg_size_mb = (sum(sizes)/len(sizes))/1e6 if sizes else 0\n",
    "    type_risks = [type_risk_map.get(a.get('type','other'), 0.4) for a in artifact_records]\n",
    "    type_risk = max(type_risks) if type_risks else 0.2\n",
    "    mission_sens = 0.0\n",
    "    ms = ingest_metadata.get('additional_metadata',{}).get('mission_sensitivity')\n",
    "    if ms:\n",
    "        if isinstance(ms, str):\n",
    "            if ms.lower().startswith('crit'): mission_sens = 2.0\n",
    "            elif ms.lower().startswith('high'): mission_sens = 1.5\n",
    "            elif ms.lower().startswith('med'): mission_sens = 1.0\n",
    "    I_base = 3.0 + (avg_size_mb * 3.0) + (type_risk * 3.0) + mission_sens\n",
    "    return round(max(0.0, min(10.0, I_base)),6)\n",
    "\n",
    "def compute_I_prime(I_base, R, Z):\n",
    "    return I_base * (1 + alpha * (1 - R)) * (1 + beta * Z)\n",
    "\n",
    "def compute_DSR_primes(DSR_base_local, H, TI):\n",
    "    DSR_prime = {}\n",
    "    for s, base in DSR_base_local.items():\n",
    "        val = base * (1 - gamma * H) * (1 + delta * TI)\n",
    "        DSR_prime[s] = clamp(val, eps, 1.0 - eps)\n",
    "    return DSR_prime\n",
    "\n",
    "def build_payoff_matrices(I_prime, DSR_prime):\n",
    "    U_a=[]; U_d=[]\n",
    "    for s in defender_strats:\n",
    "        row_a=[]; row_d=[]\n",
    "        dsr = DSR_prime[s]; asp = 1.0 - dsr\n",
    "        for a in attacker_actions:\n",
    "            ua = asp * I_prime - C_a[a]\n",
    "            if a == 'no_inject':\n",
    "                ud = - C_d[s]   # conservative: pay cost only\n",
    "            else:\n",
    "                ud = dsr * I_prime - C_d[s]\n",
    "            row_a.append(round(ua,6)); row_d.append(round(ud,6))\n",
    "        U_a.append(row_a); U_d.append(row_d)\n",
    "    return U_a, U_d\n",
    "\n",
    "def solve_stackelberg_pure(U_a, U_d):\n",
    "    best_def = None\n",
    "    for i, row in enumerate(U_a):\n",
    "        j_best = max(range(len(row)), key=lambda j: row[j])\n",
    "        ua = row[j_best]; ud = U_d[i][j_best]\n",
    "        if best_def is None or ud > best_def['ud']:\n",
    "            best_def = {'ud':ud,'ua':ua,'di':i,'aj':j_best}\n",
    "    return {'defender_strategy': defender_strats[best_def['di']],\n",
    "            'attacker_action': attacker_actions[best_def['aj']],\n",
    "            'U_d_eq': best_def['ud'], 'U_a_eq': best_def['ua']}\n",
    "\n",
    "def compute_threat_score(U_a_eq, U_d_eq, R):\n",
    "    raw = U_a_eq - U_d_eq\n",
    "    T_raw = sigmoid(kappa * raw)\n",
    "    T_S = lambda_blend * T_raw + (1.0 - lambda_blend) * (1.0 - R)\n",
    "    T_S = max(0.0, min(1.0, T_S))\n",
    "    if T_S < th_low: level=\"Low\"\n",
    "    elif T_S < th_high: level=\"Medium\"\n",
    "    else: level=\"High\"\n",
    "    return {\"raw\":round(raw,6),\"T_raw\":round(T_raw,6),\"T_S\":round(T_S,6),\"inspection_level\":level}\n",
    "\n",
    "# Example run: use the ingestion outputs here (or call estimator_pipeline per ingest)\n",
    "# (I ran the full pipeline on the sample ingestion records and saved results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c53a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3045 4.1801925 {'signature': 0.7, 'ml': 0.85, 'sandbox': 0.95} [[-0.745942, 0.0], [-1.372971, 0.0], [-1.79099, 0.0]] [[1.926135, -1.0], [0.553164, -3.0], [-2.028817, -6.0]] {'defender_index': 0, 'attacker_index': 1, 'defender_strategy': 'signature', 'attacker_action': 'no_inject', 'U_d_eq': -1.0, 'U_a_eq': 0.0} {'raw': 1.0, 'T_raw': 0.689974, 'T_S': 0.640977, 'inspection_level': 'Medium'}\n",
      "I_base = 3.3045\n",
      "I_prime = 4.180193\n",
      "DSR_prime = {'signature': 0.7, 'ml': 0.85, 'sandbox': 0.95}\n",
      "U_a (attacker payoff matrix): [[-0.745942, 0.0], [-1.372971, 0.0], [-1.79099, 0.0]]\n",
      "U_d (defender payoff matrix): [[1.926135, -1.0], [0.553164, -3.0], [-2.028817, -6.0]]\n",
      "Equilibrium: {'defender_index': 0, 'attacker_index': 1, 'defender_strategy': 'signature', 'attacker_action': 'no_inject', 'U_d_eq': -1.0, 'U_a_eq': 0.0}\n",
      "Threat Score: {'raw': 1.0, 'T_raw': 0.689974, 'T_S': 0.640977, 'inspection_level': 'Medium'}\n"
     ]
    }
   ],
   "source": [
    "# Full Threat Estimator (functions only, conservative payoffs)\n",
    "import math\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# ------------------ CONFIG (tuneable) ------------------\n",
    "alpha = 0.5\n",
    "beta = 0.3\n",
    "gamma = 0.2\n",
    "delta = 0.0\n",
    "eps = 1e-3\n",
    "\n",
    "kappa = 0.8\n",
    "lambda_blend = 0.9\n",
    "th_low = 0.4\n",
    "th_high = 0.7\n",
    "\n",
    "DSR_base = {'signature': 0.70, 'ml': 0.85, 'sandbox': 0.95}\n",
    "C_d = {'signature': 1.0, 'ml': 3.0, 'sandbox': 6.0}\n",
    "C_a = {'inject': 2.0, 'no_inject': 0.0}\n",
    "\n",
    "defender_strats = ['signature', 'ml', 'sandbox']\n",
    "attacker_actions = ['inject', 'no_inject']\n",
    "\n",
    "type_risk_map = {'telemetry': 0.1, 'text': 0.2, 'image': 0.5, 'video': 0.9, 'archive': 0.8}\n",
    "\n",
    "# ------------------ UTILITIES ------------------\n",
    "def clamp(x: float, a: float = 1e-3, b: float = 1.0 - 1e-3) -> float:\n",
    "    return max(a, min(b, x))\n",
    "\n",
    "def sigmoid(x: float) -> float:\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "# ------------------ IMPACT / DSR ------------------\n",
    "def compute_I_base(artifact_records: List[Dict[str, Any]], ingest_metadata: Dict[str, Any]) -> float:\n",
    "    sizes = [a.get('size_bytes', 0) for a in artifact_records]\n",
    "    avg_size_mb = (sum(sizes) / len(sizes)) / 1e6 if sizes else 0.0\n",
    "    type_risks = [type_risk_map.get(a.get('type', 'other'), 0.4) for a in artifact_records]\n",
    "    type_risk = max(type_risks) if type_risks else 0.2\n",
    "\n",
    "    mission_sens = 0.0\n",
    "    ms = (\n",
    "        ingest_metadata.get('additional_metadata', {}) .get('mission_sensitivity')\n",
    "        or ingest_metadata.get('notes')\n",
    "        or ingest_metadata.get('additional_metadata', {}).get('mission_sensitivity_level')\n",
    "    )\n",
    "    if ms:\n",
    "        ms_s = str(ms).lower()\n",
    "        if ms_s.startswith('crit'):\n",
    "            mission_sens = 2.0\n",
    "        elif ms_s.startswith('high'):\n",
    "            mission_sens = 1.5\n",
    "        elif ms_s.startswith('med'):\n",
    "            mission_sens = 1.0\n",
    "\n",
    "    I_base = 3.0 + (avg_size_mb * 3.0) + (type_risk * 3.0) + mission_sens\n",
    "    return round(max(0.0, min(10.0, I_base)), 6)\n",
    "\n",
    "def compute_I_prime(I_base: float, R: float, Z: float) -> float:\n",
    "    return I_base * (1 + alpha * (1 - R)) * (1 + beta * Z)\n",
    "\n",
    "def compute_DSR_primes(DSR_base_local: Dict[str, float], H: float, TI: float) -> Dict[str, float]:\n",
    "    DSR_prime: Dict[str, float] = {}\n",
    "    for s, base in DSR_base_local.items():\n",
    "        val = base * (1 - gamma * H) * (1 + delta * TI)\n",
    "        DSR_prime[s] = clamp(val, eps, 1.0 - eps)\n",
    "    return DSR_prime\n",
    "\n",
    "# ------------------ PAYOFF MATRICES (conservative) ------------------\n",
    "def build_payoff_matrices(I_prime: float, DSR_prime: Dict[str, float]) -> (List[List[float]], List[List[float]]):\n",
    "    U_a: List[List[float]] = []\n",
    "    U_d: List[List[float]] = []\n",
    "    for s in defender_strats:\n",
    "        dsr = DSR_prime[s]\n",
    "        asp = 1.0 - dsr\n",
    "        row_a: List[float] = []\n",
    "        row_d: List[float] = []\n",
    "        for a in attacker_actions:\n",
    "            # Attacker payoff: conservative -> no_inject payoff = 0\n",
    "            if a == 'no_inject':\n",
    "                ua = 0.0\n",
    "            else:\n",
    "                ua = asp * I_prime - C_a.get(a, 0.0)\n",
    "            # Defender payoff: conservative -> no_inject = -C_d[s]\n",
    "            if a == 'no_inject':\n",
    "                ud = - C_d[s]\n",
    "            else:\n",
    "                ud = dsr * I_prime - C_d[s]\n",
    "            row_a.append(round(ua, 6))\n",
    "            row_d.append(round(ud, 6))\n",
    "        U_a.append(row_a)\n",
    "        U_d.append(row_d)\n",
    "    return U_a, U_d\n",
    "\n",
    "# ------------------ STACKELBERG SOLVER (pure strategies) ------------------\n",
    "def solve_stackelberg_pure(U_a: List[List[float]], U_d: List[List[float]]) -> Dict[str, Any]:\n",
    "    best_def = None\n",
    "    for i, row in enumerate(U_a):\n",
    "        # Attacker best response(s)\n",
    "        max_ua = max(row)\n",
    "        candidates = [j for j, v in enumerate(row) if abs(v - max_ua) < 1e-12]\n",
    "        if len(candidates) == 1:\n",
    "            j_best = candidates[0]\n",
    "        else:\n",
    "            # attacker tie-breaker: pick action that minimizes U_d (hurts defender)\n",
    "            j_best = min(candidates, key=lambda j: U_d[i][j])\n",
    "        ua = row[j_best]\n",
    "        ud = U_d[i][j_best]\n",
    "        if best_def is None or ud > best_def['ud']:\n",
    "            best_def = {'di': i, 'aj': j_best, 'ud': ud, 'ua': ua}\n",
    "        elif abs(ud - best_def['ud']) < 1e-12:\n",
    "            # defender tie-breaker: prefer lower-cost strategy (choose one with smaller C_d)\n",
    "            current_cost = C_d[defender_strats[i]]\n",
    "            best_cost = C_d[defender_strats[best_def['di']]]\n",
    "            if current_cost < best_cost:\n",
    "                best_def = {'di': i, 'aj': j_best, 'ud': ud, 'ua': ua}\n",
    "    if best_def is None:\n",
    "        raise ValueError(\"Empty payoff matrices\")\n",
    "    return {\n",
    "        'defender_index': best_def['di'],\n",
    "        'attacker_index': best_def['aj'],\n",
    "        'defender_strategy': defender_strats[best_def['di']],\n",
    "        'attacker_action': attacker_actions[best_def['aj']],\n",
    "        'U_d_eq': round(best_def['ud'], 6),\n",
    "        'U_a_eq': round(best_def['ua'], 6)\n",
    "    }\n",
    "\n",
    "# ------------------ THREAT SCORE MAPPING ------------------\n",
    "def compute_threat_score(U_a_eq: float, U_d_eq: float, R: float) -> Dict[str, Any]:\n",
    "    raw = U_a_eq - U_d_eq\n",
    "    T_raw = sigmoid(kappa * raw)\n",
    "    T_S = lambda_blend * T_raw + (1.0 - lambda_blend) * (1.0 - R)\n",
    "    T_S = max(0.0, min(1.0, T_S))\n",
    "    if T_S < th_low:\n",
    "        level = \"Low\"\n",
    "    elif T_S < th_high:\n",
    "        level = \"Medium\"\n",
    "    else:\n",
    "        level = \"High\"\n",
    "    return {\"raw\": round(raw, 6), \"T_raw\": round(T_raw, 6), \"T_S\": round(T_S, 6), \"inspection_level\": level}\n",
    "\n",
    "# ------------------ (optional) Example usage ------------------\n",
    "sampleA = {\n",
    "  \"ingest_metadata\": {\n",
    "    \"ingest_id\": \"ingest_9f1a2b3c4d\",\n",
    "    \"drone_id\": \"DRN-001\",\n",
    "    \"timestamp\": \"2025-10-13T03:00:12Z\",\n",
    "    \"mission_id\": \"MSN-142\",\n",
    "    \"mission_zone\": \"zone-a\",\n",
    "    \"geo\": { \"lat\": 12.971598, \"lon\": 77.594566, \"alt\": 120 },\n",
    "    \"operator_id\": \"OP-12\",\n",
    "    \"firmware_version\": \"v1.2.0\",\n",
    "    \"num_files\": 2,\n",
    "    \"insecure_flags\": [],\n",
    "    \"auth_result\": \"ok\",\n",
    "    \"notes\": \"normal video+image feed\"\n",
    "  },\n",
    "  \"artifact_records\": [\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://a3f8e9b2c1d4\",\n",
    "      \"filename\": \"drn001_fpv_001.mp4\",\n",
    "      \"type\": \"video\",\n",
    "      \"mime\": \"video/mp4\",\n",
    "      \"size_bytes\": 4500000,\n",
    "      \"encryption\": False,\n",
    "      \"container\": False,\n",
    "      \"thumbnail\": \"thumb://6d7a8b9c0d\",\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/a3f8e9b2c1d4\"\n",
    "    },\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://b4c5d6e7f8a9\",\n",
    "      \"filename\": \"drn001_cam_001.jpg\",\n",
    "      \"type\": \"image\",\n",
    "      \"mime\": \"image/jpeg\",\n",
    "      \"size_bytes\": 320000,\n",
    "      \"encryption\": False,\n",
    "      \"container\": False,\n",
    "      \"thumbnail\": \"thumb://1a2b3c4d5e\",\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/b4c5d6e7f8a9\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "sampleB = {\n",
    "  \"ingest_metadata\": {\n",
    "    \"ingest_id\": \"ingest_c7d6e5f4a3\",\n",
    "    \"drone_id\": \"DRN-002\",\n",
    "    \"timestamp\": \"2025-10-13T03:05:45Z\",\n",
    "    \"mission_id\": \"MSN-143\",\n",
    "    \"mission_zone\": \"zone-c\",\n",
    "    \"geo\": { \"lat\": 13.035542, \"lon\": 77.597100, \"alt\": 85 },\n",
    "    \"operator_id\": \"OP-23\",\n",
    "    \"firmware_version\": \"v1.1.9\",\n",
    "    \"num_files\": 2,\n",
    "    \"insecure_flags\": [\"encrypted_payload\", \"nested_archive\"],\n",
    "    \"auth_result\": \"unknown\",\n",
    "    \"notes\": \"encrypted ZIP with nested contents — flag for deferred analysis\"\n",
    "  },\n",
    "  \"artifact_records\": [\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://c1d2e3f4a5b6\",\n",
    "      \"filename\": \"payload_bundle.zip\",\n",
    "      \"type\": \"archive\",\n",
    "      \"mime\": \"application/zip\",\n",
    "      \"size_bytes\": 4200000,\n",
    "      \"encryption\": True,\n",
    "      \"container\": True,\n",
    "      \"thumbnail\": None,\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/c1d2e3f4a5b6\"\n",
    "    },\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://d7e8f9a0b1c2\",\n",
    "      \"filename\": \"notes.txt\",\n",
    "      \"type\": \"text\",\n",
    "      \"mime\": \"text/plain\",\n",
    "      \"size_bytes\": 2048,\n",
    "      \"encryption\": False,\n",
    "      \"container\": False,\n",
    "      \"thumbnail\": None,\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/d7e8f9a0b1c2\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "sampleC = {\n",
    "  \"ingest_metadata\": {\n",
    "    \"ingest_id\": \"ingest_e8f7g6h5i4\",\n",
    "    \"drone_id\": \"DRN-003\",\n",
    "    \"timestamp\": \"2025-10-13T03:10:03Z\",\n",
    "    \"mission_id\": \"MSN-144\",\n",
    "    \"mission_zone\": \"zone-b\",\n",
    "    \"geo\": { \"lat\": 12.967800, \"lon\": 77.601200, \"alt\": 35 },\n",
    "    \"operator_id\": \"OP-33\",\n",
    "    \"firmware_version\": \"v1.2.3\",\n",
    "    \"num_files\": 1,\n",
    "    \"insecure_flags\": [],\n",
    "    \"auth_result\": \"ok\",\n",
    "    \"notes\": \"telemetry-only — low risk\"\n",
    "  },\n",
    "  \"artifact_records\": [\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://e9f0g1h2i3j4\",\n",
    "      \"filename\": \"telemetry_snapshot.json\",\n",
    "      \"type\": \"telemetry\",\n",
    "      \"mime\": \"application/json\",\n",
    "      \"size_bytes\": 1500,\n",
    "      \"encryption\": False,\n",
    "      \"container\": False,\n",
    "      \"thumbnail\": None,\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/e9f0g1h2i3j4\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "sampleD = {\n",
    "  \"ingest_metadata\": {\n",
    "    \"ingest_id\": \"ingest_f1e2d3c4b5\",\n",
    "    \"drone_id\": \"DRN-004\",\n",
    "    \"timestamp\": \"2025-10-13T03:15:22Z\",\n",
    "    \"mission_id\": \"MSN-145\",\n",
    "    \"mission_zone\": \"zone-a\",\n",
    "    \"geo\": { \"lat\": 12.975000, \"lon\": 77.590000, \"alt\": 200 },\n",
    "    \"operator_id\": \"OP-05\",\n",
    "    \"firmware_version\": \"v2.0.0\",\n",
    "    \"num_files\": 2,\n",
    "    \"insecure_flags\": [],\n",
    "    \"auth_result\": \"ok\",\n",
    "    \"notes\": \"large survey video — mission sensitivity: critical\"\n",
    "  },\n",
    "  \"artifact_records\": [\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://f2e3d4c5b6a7\",\n",
    "      \"filename\": \"survey_coverage_long.mp4\",\n",
    "      \"type\": \"video\",\n",
    "      \"mime\": \"video/mp4\",\n",
    "      \"size_bytes\": 12500000,\n",
    "      \"encryption\": False,\n",
    "      \"container\": False,\n",
    "      \"thumbnail\": \"thumb://abc123def456\",\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/f2e3d4c5b6a7\"\n",
    "    },\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://g3h4i5j6k7l8\",\n",
    "      \"filename\": \"survey_frame_2345.jpg\",\n",
    "      \"type\": \"image\",\n",
    "      \"mime\": \"image/jpeg\",\n",
    "      \"size_bytes\": 550000,\n",
    "      \"encryption\": False,\n",
    "      \"container\": False,\n",
    "      \"thumbnail\": \"thumb://789xyz456\",\n",
    "      \"pointer_storage\": \"s3://forensics/artifacts/g3h4i5j6k7l8\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "sampleHighRisk =sampleHighRisk = {\n",
    "  \"ingest_metadata\": {\n",
    "    \"ingest_id\": \"ingest_high_999\",\n",
    "    \"drone_id\": \"DRN-999\",\n",
    "    \"timestamp\": \"2025-10-14T04:45:00Z\",\n",
    "    \"mission_id\": \"MSN-999\",\n",
    "    \"mission_zone\": \"zone-x\",\n",
    "    \"geo\": { \"lat\": 27.175, \"lon\": 78.042, \"alt\": 250 },\n",
    "    \"operator_id\": \"OP-99\",\n",
    "    \"firmware_version\": \"v0.9.1\",\n",
    "    \"num_files\": 3,\n",
    "    \"insecure_flags\": [\"encrypted_payload\", \"nested_archive\"],\n",
    "    \"auth_result\": \"fail\",\n",
    "    \"notes\": \"critical mission, unverified source, encrypted nested archive payload\"\n",
    "  },\n",
    "  \"artifact_records\": [\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://risk001\",\n",
    "      \"filename\": \"payload_secure_bundle.zip\",\n",
    "      \"type\": \"archive\",\n",
    "      \"mime\": \"application/zip\",\n",
    "      \"size_bytes\": 18000000,   # 18 MB\n",
    "      \"encryption\": True,\n",
    "      \"container\": True,\n",
    "      \"thumbnail\": None,\n",
    "      \"pointer_storage\": \"s3://forensics/highrisk/payload_secure_bundle.zip\"\n",
    "    },\n",
    "    {\n",
    "      \"artifact_id\": \"artifact://risk002\",\n",
    "      \"filename\": \"readme.txt\",\n",
    "      \"type\": \"text\",\n",
    "      \"mime\": \"text/plain\",\n",
    "      \"size_bytes\": 4000,\n",
    "      \"encryption\": False,\n",
    "      \"container\": False,\n",
    "      \"thumbnail\": None,\n",
    "      \"pointer_storage\": \"s3://forensics/highrisk/readme.txt\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "# provide ingest metadata + artifact_records\n",
    "ingestion = sampleC\n",
    "R = 0.8; Z = 0.5; H = 0.0; TI = 0.0\n",
    "I_base = compute_I_base(ingestion['artifact_records'], ingestion['ingest_metadata'])\n",
    "I_prime = compute_I_prime(I_base, R, Z)\n",
    "DSR_prime = compute_DSR_primes(DSR_base, H, TI)\n",
    "U_a, U_d = build_payoff_matrices(I_prime, DSR_prime)\n",
    "eq = solve_stackelberg_pure(U_a, U_d)\n",
    "threat = compute_threat_score(eq['U_a_eq'], eq['U_d_eq'], R)\n",
    "print(I_base, I_prime, DSR_prime, U_a, U_d, eq, threat)\n",
    "print(\"I_base =\", I_base)\n",
    "print(\"I_prime =\", round(I_prime, 6))\n",
    "print(\"DSR_prime =\", {k: round(v, 6) for k, v in DSR_prime.items()})\n",
    "print(\"U_a (attacker payoff matrix):\", U_a)\n",
    "print(\"U_d (defender payoff matrix):\", U_d)\n",
    "print(\"Equilibrium:\", eq)\n",
    "print(\"Threat Score:\", threat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d607ff",
   "metadata": {},
   "source": [
    "# Tentative Future Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1875d084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BAYESIAN-STACKELBERG THREAT ESTIMATOR - RESULTS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SAMPLE A: DRN-001\n",
      "================================================================================\n",
      "{\n",
      "  \"ingest_id\": \"ingest_9f1a2b3c4d\",\n",
      "  \"drone_id\": \"DRN-001\",\n",
      "  \"timestamp\": \"2025-10-13T03:00:12Z\",\n",
      "  \"inputs\": {\n",
      "    \"I_base\": 10.0,\n",
      "    \"I_prime\": 11.99,\n",
      "    \"R\": 0.8,\n",
      "    \"Z\": 0.3,\n",
      "    \"H\": 0.0,\n",
      "    \"TI\": 0.0,\n",
      "    \"DSR_prime\": {\n",
      "      \"signature\": 0.7,\n",
      "      \"ml\": 0.85,\n",
      "      \"sandbox\": 0.95\n",
      "    }\n",
      "  },\n",
      "  \"bayesian\": {\n",
      "    \"T_S_bayesian\": 0.028934,\n",
      "    \"raw_bayesian\": -7.228055,\n",
      "    \"inspection_level\": \"Low\",\n",
      "    \"type_breakdown\": {\n",
      "      \"opportunistic\": {\n",
      "        \"prior\": 0.7,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.805,\n",
      "          \"ml\": 0.935,\n",
      "          \"sandbox\": 0.9975\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 0,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"signature\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 8.65195,\n",
      "          \"U_a_eq\": 0.33805\n",
      "        },\n",
      "        \"raw\": -8.3139,\n",
      "        \"T_S\": 0.021162,\n",
      "        \"sophistication\": 0.2\n",
      "      },\n",
      "      \"insider\": {\n",
      "        \"prior\": 0.2,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.595,\n",
      "          \"ml\": 0.765,\n",
      "          \"sandbox\": 0.9025\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 1,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"ml\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 6.17235,\n",
      "          \"U_a_eq\": 0.81765\n",
      "        },\n",
      "        \"raw\": -5.3547,\n",
      "        \"T_S\": 0.032243,\n",
      "        \"sophistication\": 0.5\n",
      "      },\n",
      "      \"apt\": {\n",
      "        \"prior\": 0.1,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.28,\n",
      "          \"ml\": 0.51,\n",
      "          \"sandbox\": 0.8075\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 2,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"sandbox\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 3.681925,\n",
      "          \"U_a_eq\": 0.308075\n",
      "        },\n",
      "        \"raw\": -3.37385,\n",
      "        \"T_S\": 0.076725,\n",
      "        \"sophistication\": 0.9\n",
      "      }\n",
      "    },\n",
      "    \"attacker_priors\": {\n",
      "      \"opportunistic\": 0.7,\n",
      "      \"insider\": 0.2,\n",
      "      \"apt\": 0.1\n",
      "    }\n",
      "  },\n",
      "  \"standard_stackelberg\": {\n",
      "    \"T_S\": 0.028636,\n",
      "    \"inspection_level\": \"Low\",\n",
      "    \"equilibrium\": {\n",
      "      \"defender_index\": 0,\n",
      "      \"attacker_index\": 0,\n",
      "      \"defender_strategy\": \"signature\",\n",
      "      \"attacker_action\": \"inject\",\n",
      "      \"U_d_eq\": 7.393,\n",
      "      \"U_a_eq\": 1.597\n",
      "    },\n",
      "    \"raw\": -5.796\n",
      "  },\n",
      "  \"parameters\": {\n",
      "    \"alpha\": 0.5,\n",
      "    \"beta\": 0.3,\n",
      "    \"gamma\": 0.2,\n",
      "    \"delta\": 0.1,\n",
      "    \"kappa\": 0.8,\n",
      "    \"lambda_blend\": 0.9,\n",
      "    \"th_low\": 0.4,\n",
      "    \"th_high\": 0.7\n",
      "  }\n",
      "}\n",
      "\n",
      "[Feedback] Bayesian level=Low -> updated reputation for DRN-001: 0.820\n",
      "\n",
      "================================================================================\n",
      "SAMPLE B: DRN-002\n",
      "================================================================================\n",
      "{\n",
      "  \"ingest_id\": \"ingest_c7d6e5f4a3\",\n",
      "  \"drone_id\": \"DRN-002\",\n",
      "  \"timestamp\": null,\n",
      "  \"inputs\": {\n",
      "    \"I_base\": 10.0,\n",
      "    \"I_prime\": 13.31,\n",
      "    \"R\": 0.8,\n",
      "    \"Z\": 0.7,\n",
      "    \"H\": 0.0,\n",
      "    \"TI\": 0.3,\n",
      "    \"DSR_prime\": {\n",
      "      \"signature\": 0.721,\n",
      "      \"ml\": 0.8755,\n",
      "      \"sandbox\": 0.9785\n",
      "    }\n",
      "  },\n",
      "  \"bayesian\": {\n",
      "    \"T_S_bayesian\": 0.026027,\n",
      "    \"raw_bayesian\": -7.505659,\n",
      "    \"inspection_level\": \"Low\",\n",
      "    \"type_breakdown\": {\n",
      "      \"opportunistic\": {\n",
      "        \"prior\": 0.410509,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.82915,\n",
      "          \"ml\": 0.96305,\n",
      "          \"sandbox\": 0.999\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 0,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"signature\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 10.035986,\n",
      "          \"U_a_eq\": 0.274014\n",
      "        },\n",
      "        \"raw\": -9.761972,\n",
      "        \"T_S\": 0.020365,\n",
      "        \"sophistication\": 0.2\n",
      "      },\n",
      "      \"insider\": {\n",
      "        \"prior\": 0.35468,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.61285,\n",
      "          \"ml\": 0.78795,\n",
      "          \"sandbox\": 0.929575\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 1,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"ml\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 7.487614,\n",
      "          \"U_a_eq\": 0.822386\n",
      "        },\n",
      "        \"raw\": -6.665228,\n",
      "        \"T_S\": 0.024329,\n",
      "        \"sophistication\": 0.5\n",
      "      },\n",
      "      \"apt\": {\n",
      "        \"prior\": 0.234811,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.2884,\n",
      "          \"ml\": 0.5253,\n",
      "          \"sandbox\": 0.831725\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 2,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"sandbox\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 5.07026,\n",
      "          \"U_a_eq\": 0.23974\n",
      "        },\n",
      "        \"raw\": -4.83052,\n",
      "        \"T_S\": 0.03849,\n",
      "        \"sophistication\": 0.9\n",
      "      }\n",
      "    },\n",
      "    \"attacker_priors\": {\n",
      "      \"opportunistic\": 0.41050903119868637,\n",
      "      \"insider\": 0.35467980295566504,\n",
      "      \"apt\": 0.23481116584564862\n",
      "    }\n",
      "  },\n",
      "  \"standard_stackelberg\": {\n",
      "    \"T_S\": 0.02364,\n",
      "    \"inspection_level\": \"Low\",\n",
      "    \"equilibrium\": {\n",
      "      \"defender_index\": 0,\n",
      "      \"attacker_index\": 0,\n",
      "      \"defender_strategy\": \"signature\",\n",
      "      \"attacker_action\": \"inject\",\n",
      "      \"U_d_eq\": 8.59651,\n",
      "      \"U_a_eq\": 1.71349\n",
      "    },\n",
      "    \"raw\": -6.88302\n",
      "  },\n",
      "  \"parameters\": {\n",
      "    \"alpha\": 0.5,\n",
      "    \"beta\": 0.3,\n",
      "    \"gamma\": 0.2,\n",
      "    \"delta\": 0.1,\n",
      "    \"kappa\": 0.8,\n",
      "    \"lambda_blend\": 0.9,\n",
      "    \"th_low\": 0.4,\n",
      "    \"th_high\": 0.7\n",
      "  }\n",
      "}\n",
      "\n",
      "[Feedback] Bayesian level=Low -> updated reputation for DRN-002: 0.820\n",
      "\n",
      "================================================================================\n",
      "SAMPLE C: DRN-003\n",
      "================================================================================\n",
      "{\n",
      "  \"ingest_id\": \"ingest_e8f7g6h5i4\",\n",
      "  \"drone_id\": \"DRN-003\",\n",
      "  \"timestamp\": null,\n",
      "  \"inputs\": {\n",
      "    \"I_base\": 3.3045,\n",
      "    \"I_prime\": 4.180193,\n",
      "    \"R\": 0.8,\n",
      "    \"Z\": 0.5,\n",
      "    \"H\": 0.0,\n",
      "    \"TI\": 0.0,\n",
      "    \"DSR_prime\": {\n",
      "      \"signature\": 0.7,\n",
      "      \"ml\": 0.85,\n",
      "      \"sandbox\": 0.95\n",
      "    }\n",
      "  },\n",
      "  \"bayesian\": {\n",
      "    \"T_S_bayesian\": 0.638443,\n",
      "    \"raw_bayesian\": 0.983928,\n",
      "    \"inspection_level\": \"Medium\",\n",
      "    \"type_breakdown\": {\n",
      "      \"opportunistic\": {\n",
      "        \"prior\": 0.7,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.805,\n",
      "          \"ml\": 0.935,\n",
      "          \"sandbox\": 0.9975\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 0,\n",
      "          \"attacker_index\": 1,\n",
      "          \"defender_strategy\": \"signature\",\n",
      "          \"attacker_action\": \"no_inject\",\n",
      "          \"U_d_eq\": -1.0,\n",
      "          \"U_a_eq\": 0.0\n",
      "        },\n",
      "        \"raw\": 1.0,\n",
      "        \"T_S\": 0.640977,\n",
      "        \"sophistication\": 0.2\n",
      "      },\n",
      "      \"insider\": {\n",
      "        \"prior\": 0.2,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.595,\n",
      "          \"ml\": 0.765,\n",
      "          \"sandbox\": 0.9025\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 0,\n",
      "          \"attacker_index\": 1,\n",
      "          \"defender_strategy\": \"signature\",\n",
      "          \"attacker_action\": \"no_inject\",\n",
      "          \"U_d_eq\": -1.0,\n",
      "          \"U_a_eq\": 0.0\n",
      "        },\n",
      "        \"raw\": 1.0,\n",
      "        \"T_S\": 0.640977,\n",
      "        \"sophistication\": 0.5\n",
      "      },\n",
      "      \"apt\": {\n",
      "        \"prior\": 0.1,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.28,\n",
      "          \"ml\": 0.51,\n",
      "          \"sandbox\": 0.8075\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 0,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"signature\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 0.170454,\n",
      "          \"U_a_eq\": 1.009739\n",
      "        },\n",
      "        \"raw\": 0.839285,\n",
      "        \"T_S\": 0.615641,\n",
      "        \"sophistication\": 0.9\n",
      "      }\n",
      "    },\n",
      "    \"attacker_priors\": {\n",
      "      \"opportunistic\": 0.7,\n",
      "      \"insider\": 0.2,\n",
      "      \"apt\": 0.1\n",
      "    }\n",
      "  },\n",
      "  \"standard_stackelberg\": {\n",
      "    \"T_S\": 0.640977,\n",
      "    \"inspection_level\": \"Medium\",\n",
      "    \"equilibrium\": {\n",
      "      \"defender_index\": 0,\n",
      "      \"attacker_index\": 1,\n",
      "      \"defender_strategy\": \"signature\",\n",
      "      \"attacker_action\": \"no_inject\",\n",
      "      \"U_d_eq\": -1.0,\n",
      "      \"U_a_eq\": 0.0\n",
      "    },\n",
      "    \"raw\": 1.0\n",
      "  },\n",
      "  \"parameters\": {\n",
      "    \"alpha\": 0.5,\n",
      "    \"beta\": 0.3,\n",
      "    \"gamma\": 0.2,\n",
      "    \"delta\": 0.1,\n",
      "    \"kappa\": 0.8,\n",
      "    \"lambda_blend\": 0.9,\n",
      "    \"th_low\": 0.4,\n",
      "    \"th_high\": 0.7\n",
      "  }\n",
      "}\n",
      "\n",
      "[Feedback] Bayesian level=Medium -> updated reputation for DRN-003: 0.750\n",
      "\n",
      "================================================================================\n",
      "SAMPLE High-Risk: DRN-999\n",
      "================================================================================\n",
      "{\n",
      "  \"ingest_id\": \"ingest_high_999\",\n",
      "  \"drone_id\": \"DRN-999\",\n",
      "  \"timestamp\": null,\n",
      "  \"inputs\": {\n",
      "    \"I_base\": 10.0,\n",
      "    \"I_prime\": 13.97,\n",
      "    \"R\": 0.8,\n",
      "    \"Z\": 0.9,\n",
      "    \"H\": 0.0,\n",
      "    \"TI\": 0.0,\n",
      "    \"DSR_prime\": {\n",
      "      \"signature\": 0.7,\n",
      "      \"ml\": 0.85,\n",
      "      \"sandbox\": 0.95\n",
      "    }\n",
      "  },\n",
      "  \"bayesian\": {\n",
      "    \"T_S_bayesian\": 0.032922,\n",
      "    \"raw_bayesian\": -5.92423,\n",
      "    \"inspection_level\": \"Low\",\n",
      "    \"type_breakdown\": {\n",
      "      \"opportunistic\": {\n",
      "        \"prior\": 0.127796,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.805,\n",
      "          \"ml\": 0.935,\n",
      "          \"sandbox\": 0.9975\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 0,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"signature\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 10.24585,\n",
      "          \"U_a_eq\": 0.72415\n",
      "        },\n",
      "        \"raw\": -9.5217,\n",
      "        \"T_S\": 0.020442,\n",
      "        \"sophistication\": 0.2\n",
      "      },\n",
      "      \"insider\": {\n",
      "        \"prior\": 0.387646,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.595,\n",
      "          \"ml\": 0.765,\n",
      "          \"sandbox\": 0.9025\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 1,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"ml\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 7.68705,\n",
      "          \"U_a_eq\": 1.28295\n",
      "        },\n",
      "        \"raw\": -6.4041,\n",
      "        \"T_S\": 0.025329,\n",
      "        \"sophistication\": 0.5\n",
      "      },\n",
      "      \"apt\": {\n",
      "        \"prior\": 0.484558,\n",
      "        \"DSR_adjusted\": {\n",
      "          \"signature\": 0.28,\n",
      "          \"ml\": 0.51,\n",
      "          \"sandbox\": 0.8075\n",
      "        },\n",
      "        \"equilibrium\": {\n",
      "          \"defender_index\": 2,\n",
      "          \"attacker_index\": 0,\n",
      "          \"defender_strategy\": \"sandbox\",\n",
      "          \"attacker_action\": \"inject\",\n",
      "          \"U_d_eq\": 5.280775,\n",
      "          \"U_a_eq\": 0.689225\n",
      "        },\n",
      "        \"raw\": -4.59155,\n",
      "        \"T_S\": 0.042289,\n",
      "        \"sophistication\": 0.9\n",
      "      }\n",
      "    },\n",
      "    \"attacker_priors\": {\n",
      "      \"opportunistic\": 0.12779552715654952,\n",
      "      \"insider\": 0.38764643237486685,\n",
      "      \"apt\": 0.4845580404685836\n",
      "    }\n",
      "  },\n",
      "  \"standard_stackelberg\": {\n",
      "    \"T_S\": 0.020801,\n",
      "    \"inspection_level\": \"Low\",\n",
      "    \"equilibrium\": {\n",
      "      \"defender_index\": 1,\n",
      "      \"attacker_index\": 0,\n",
      "      \"defender_strategy\": \"ml\",\n",
      "      \"attacker_action\": \"inject\",\n",
      "      \"U_d_eq\": 8.8745,\n",
      "      \"U_a_eq\": 0.0955\n",
      "    },\n",
      "    \"raw\": -8.779\n",
      "  },\n",
      "  \"parameters\": {\n",
      "    \"alpha\": 0.5,\n",
      "    \"beta\": 0.3,\n",
      "    \"gamma\": 0.2,\n",
      "    \"delta\": 0.1,\n",
      "    \"kappa\": 0.8,\n",
      "    \"lambda_blend\": 0.9,\n",
      "    \"th_low\": 0.4,\n",
      "    \"th_high\": 0.7\n",
      "  }\n",
      "}\n",
      "\n",
      "[Feedback] Bayesian level=Low -> updated reputation for DRN-999: 0.820\n",
      "\n",
      "================================================================================\n",
      "Done. Reputations database snapshot:\n",
      "{\n",
      "  \"DRN-001\": 0.8200000000000001,\n",
      "  \"DRN-002\": 0.8200000000000001,\n",
      "  \"DRN-003\": 0.75,\n",
      "  \"DRN-999\": 0.8200000000000001\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# GAME-THEORETIC THREAT ESTIMATOR WITH BAYESIAN MODELING\n",
    "# Enhanced version with Stackelberg + Bayesian game integration\n",
    "# ============================================================================\n",
    "\n",
    "import math\n",
    "import json\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS (Tuneable)\n",
    "# ============================================================================\n",
    "\n",
    "# Impact adjustment weights\n",
    "alpha = 0.5  # Reputation influence on impact\n",
    "beta = 0.3   # Zone risk influence on impact\n",
    "gamma = 0.2  # History effect on detection\n",
    "delta = 0.1  # TI boost effect on detection (increased from 0.0)\n",
    "eps = 1e-3   # Clamp epsilon\n",
    "\n",
    "# Threat score mapping\n",
    "kappa = 0.8         # Sigmoid scale\n",
    "lambda_blend = 0.9  # Model vs reputation weight\n",
    "th_low = 0.4        # Low/Medium threshold\n",
    "th_high = 0.7       # Medium/High threshold\n",
    "\n",
    "# Base detection success rates\n",
    "DSR_base = {\n",
    "    'signature': 0.70,\n",
    "    'ml': 0.85,\n",
    "    'sandbox': 0.95\n",
    "}\n",
    "\n",
    "# Defender costs (abstract units)\n",
    "C_d = {\n",
    "    'signature': 1.0,\n",
    "    'ml': 3.0,\n",
    "    'sandbox': 6.0\n",
    "}\n",
    "\n",
    "# Attacker costs\n",
    "C_a = {\n",
    "    'inject': 2.0,\n",
    "    'no_inject': 0.0\n",
    "}\n",
    "\n",
    "# Strategy lists\n",
    "defender_strats = ['signature', 'ml', 'sandbox']\n",
    "attacker_actions = ['inject', 'no_inject']\n",
    "\n",
    "# File type risk mapping\n",
    "type_risk_map = {\n",
    "    'telemetry': 0.1,\n",
    "    'text': 0.2,\n",
    "    'image': 0.5,\n",
    "    'video': 0.9,\n",
    "    'archive': 0.8\n",
    "}\n",
    "\n",
    "# Zone risk mapping (NEW)\n",
    "ZONE_RISK_MAP = {\n",
    "    'zone-a': 0.3,   # Safe base\n",
    "    'zone-b': 0.5,   # Neutral patrol area\n",
    "    'zone-c': 0.7,   # Elevated risk zone\n",
    "    'zone-x': 0.9,   # Conflict/high-risk area\n",
    "    'default': 0.5\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# BAYESIAN GAME MODELING - ATTACKER TYPE DEFINITIONS (NEW)\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class AttackerType:\n",
    "    \"\"\"Represents an attacker type with specific capabilities\"\"\"\n",
    "    name: str\n",
    "    dsr_multipliers: Dict[str, float]  # How this type affects detection rates\n",
    "    sophistication: float  # 0-1 scale\n",
    "    description: str\n",
    "\n",
    "# Define attacker type profiles\n",
    "ATTACKER_TYPES = {\n",
    "    'opportunistic': AttackerType(\n",
    "        name='opportunistic',\n",
    "        dsr_multipliers={\n",
    "            'signature': 1.15,  # Known malware, easier to detect\n",
    "            'ml': 1.10,\n",
    "            'sandbox': 1.05\n",
    "        },\n",
    "        sophistication=0.2,\n",
    "        description='Script kiddies using known malware'\n",
    "    ),\n",
    "    'insider': AttackerType(\n",
    "        name='insider',\n",
    "        dsr_multipliers={\n",
    "            'signature': 0.85,  # May evade basic signatures\n",
    "            'ml': 0.90,\n",
    "            'sandbox': 0.95\n",
    "        },\n",
    "        sophistication=0.5,\n",
    "        description='Insider threat with system knowledge'\n",
    "    ),\n",
    "    'apt': AttackerType(\n",
    "        name='apt',\n",
    "        dsr_multipliers={\n",
    "            'signature': 0.40,  # Zero-days, advanced evasion\n",
    "            'ml': 0.60,\n",
    "            'sandbox': 0.85\n",
    "        },\n",
    "        sophistication=0.9,\n",
    "        description='Advanced Persistent Threat / Nation-state'\n",
    "    )\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# BAYESIAN PRIORS - CONTEXT-DEPENDENT (NEW)\n",
    "# ============================================================================\n",
    "\n",
    "def get_attacker_type_priors(mission_zone: str, \n",
    "                             insecure_flags: List[str],\n",
    "                             auth_result: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute prior probabilities for attacker types based on context.\n",
    "    Uses mission zone, security flags, and authentication results.\n",
    "    \n",
    "    Args:\n",
    "        mission_zone: Geographic zone identifier\n",
    "        insecure_flags: List of security warning flags\n",
    "        auth_result: Authentication result ('ok', 'unknown', 'fail')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping attacker type names to prior probabilities\n",
    "    \"\"\"\n",
    "    # Base priors (default assumption)\n",
    "    base_priors = {\n",
    "        'opportunistic': 0.70,\n",
    "        'insider': 0.20,\n",
    "        'apt': 0.10\n",
    "    }\n",
    "    \n",
    "    # Adjust based on zone risk\n",
    "    zone_risk = ZONE_RISK_MAP.get(mission_zone, ZONE_RISK_MAP['default'])\n",
    "    \n",
    "    if zone_risk >= 0.8:  # High-risk zone (conflict area)\n",
    "        priors = {\n",
    "            'opportunistic': 0.30,\n",
    "            'insider': 0.35,\n",
    "            'apt': 0.35  # Much higher APT probability\n",
    "        }\n",
    "    elif zone_risk >= 0.6:  # Medium-high risk\n",
    "        priors = {\n",
    "            'opportunistic': 0.50,\n",
    "            'insider': 0.30,\n",
    "            'apt': 0.20\n",
    "        }\n",
    "    else:  # Low-medium risk\n",
    "        priors = base_priors.copy()\n",
    "    \n",
    "    # Adjust based on authentication result\n",
    "    if auth_result == 'fail':\n",
    "        # Failed auth suggests more sophisticated attack\n",
    "        priors['apt'] *= 1.5\n",
    "        priors['insider'] *= 1.3\n",
    "        priors['opportunistic'] *= 0.6\n",
    "    elif auth_result == 'unknown':\n",
    "        priors['insider'] *= 1.2\n",
    "        priors['apt'] *= 1.1\n",
    "    \n",
    "    # Adjust based on insecure flags\n",
    "    suspicious_flag_count = len(insecure_flags)\n",
    "    if suspicious_flag_count >= 2:\n",
    "        # Multiple red flags suggest sophistication\n",
    "        priors['apt'] *= 1.3\n",
    "        priors['insider'] *= 1.2\n",
    "    \n",
    "    # Normalize to sum to 1.0\n",
    "    total = sum(priors.values())\n",
    "    priors = {k: v/total for k, v in priors.items()}\n",
    "    \n",
    "    return priors\n",
    "\n",
    "# ============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def clamp(x: float, a: float = 1e-3, b: float = 1.0 - 1e-3) -> float:\n",
    "    \"\"\"Clamp value between a and b\"\"\"\n",
    "    return max(a, min(b, x))\n",
    "\n",
    "def sigmoid(x: float) -> float:\n",
    "    \"\"\"Sigmoid function for normalization\"\"\"\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def get_zone_risk(mission_zone: str) -> float:\n",
    "    \"\"\"Get risk score for a mission zone\"\"\"\n",
    "    return ZONE_RISK_MAP.get(mission_zone, ZONE_RISK_MAP['default'])\n",
    "\n",
    "# ============================================================================\n",
    "# REPUTATION MANAGEMENT (NEW - ENHANCED)\n",
    "# ============================================================================\n",
    "\n",
    "class ReputationManager:\n",
    "    \"\"\"Manages drone reputation scores with learning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reputation_db: Dict[str, float] = {}\n",
    "        self.default_reputation = 0.8\n",
    "        self.history_window = 10\n",
    "        self.drone_history: Dict[str, List[str]] = {}\n",
    "    \n",
    "    def get_reputation(self, drone_id: str) -> float:\n",
    "        \"\"\"Get current reputation for a drone\"\"\"\n",
    "        return self.reputation_db.get(drone_id, self.default_reputation)\n",
    "    \n",
    "    def get_infection_history(self, drone_id: str) -> float:\n",
    "        \"\"\"\n",
    "        Get recent infection rate for a drone (parameter H)\n",
    "        Returns fraction of recent feeds that were malicious\n",
    "        \"\"\"\n",
    "        if drone_id not in self.drone_history:\n",
    "            return 0.0\n",
    "        \n",
    "        history = self.drone_history[drone_id][-self.history_window:]\n",
    "        if not history:\n",
    "            return 0.0\n",
    "        \n",
    "        infected_count = sum(1 for status in history if status == 'malicious')\n",
    "        return infected_count / len(history)\n",
    "    \n",
    "    def update_reputation(self, drone_id: str, detection_result: str):\n",
    "        \"\"\"\n",
    "        Update reputation based on detection result (feedback loop)\n",
    "        \n",
    "        Args:\n",
    "            drone_id: Drone identifier\n",
    "            detection_result: 'clean', 'suspicious', or 'malicious'\n",
    "        \"\"\"\n",
    "        current_rep = self.get_reputation(drone_id)\n",
    "        \n",
    "        # Update reputation\n",
    "        if detection_result == 'malicious':\n",
    "            new_rep = max(0.1, current_rep - 0.15)  # Significant penalty\n",
    "        elif detection_result == 'suspicious':\n",
    "            new_rep = max(0.1, current_rep - 0.05)  # Minor penalty\n",
    "        elif detection_result == 'clean':\n",
    "            new_rep = min(1.0, current_rep + 0.02)  # Slow reward\n",
    "        else:\n",
    "            new_rep = current_rep\n",
    "        \n",
    "        self.reputation_db[drone_id] = new_rep\n",
    "        \n",
    "        # Update history\n",
    "        if drone_id not in self.drone_history:\n",
    "            self.drone_history[drone_id] = []\n",
    "        self.drone_history[drone_id].append(detection_result)\n",
    "        \n",
    "        # Keep only recent history\n",
    "        if len(self.drone_history[drone_id]) > self.history_window * 2:\n",
    "            self.drone_history[drone_id] = self.drone_history[drone_id][-self.history_window:]\n",
    "\n",
    "# ============================================================================\n",
    "# THREAT INTELLIGENCE CORRELATION (NEW - ENHANCED)\n",
    "# ============================================================================\n",
    "\n",
    "class ThreatIntelligenceCorrelator:\n",
    "    \"\"\"Correlates artifacts with known threat intelligence\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # In production: Connect to MISP, STIX/TAXII feeds, etc.\n",
    "        self.known_iocs: Dict[str, float] = {}  # checksum -> severity\n",
    "        self.suspicious_patterns: List[Dict] = []\n",
    "    \n",
    "    def add_ioc(self, checksum: str, severity: float):\n",
    "        \"\"\"Add an Indicator of Compromise\"\"\"\n",
    "        self.known_iocs[checksum] = severity\n",
    "    \n",
    "    def correlate(self, artifact_records: List[Dict]) -> float:\n",
    "        \"\"\"\n",
    "        Check artifacts against threat intelligence\n",
    "        Returns TI boost factor [0, 1]\n",
    "        \"\"\"\n",
    "        ti_boost = 0.0\n",
    "        \n",
    "        for artifact in artifact_records:\n",
    "            checksum = artifact.get('checksum', '')\n",
    "            \n",
    "            # Check against known IOCs\n",
    "            if checksum in self.known_iocs:\n",
    "                ti_boost = max(ti_boost, self.known_iocs[checksum])\n",
    "            \n",
    "            # Check for suspicious patterns\n",
    "            if artifact.get('encryption') and artifact.get('container'):\n",
    "                ti_boost = max(ti_boost, 0.3)  # Encrypted archives suspicious\n",
    "            \n",
    "            # Large binary files\n",
    "            if artifact.get('size_bytes', 0) > 50_000_000:  # > 50MB\n",
    "                ti_boost = max(ti_boost, 0.2)\n",
    "        \n",
    "        return min(1.0, ti_boost)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: COMPUTE BASE IMPACT (I_base)\n",
    "# ============================================================================\n",
    "\n",
    "def compute_I_base(artifact_records: List[Dict[str, Any]], \n",
    "                   ingest_metadata: Dict[str, Any]) -> float:\n",
    "    \"\"\"\n",
    "    Compute base impact score from artifact characteristics.\n",
    "    \n",
    "    Args:\n",
    "        artifact_records: List of artifact metadata\n",
    "        ingest_metadata: Ingestion metadata including mission info\n",
    "    \n",
    "    Returns:\n",
    "        Base impact score [0, 10]\n",
    "    \"\"\"\n",
    "    if not artifact_records:\n",
    "        raise ValueError(\"artifact_records cannot be empty\")\n",
    "    \n",
    "    # Average file size in MB\n",
    "    sizes = [a.get('size_bytes', 0) for a in artifact_records]\n",
    "    avg_size_mb = (sum(sizes) / len(sizes)) / 1e6 if sizes else 0.0\n",
    "    \n",
    "    # Maximum type risk\n",
    "    type_risks = [type_risk_map.get(a.get('type', 'other'), 0.4) \n",
    "                  for a in artifact_records]\n",
    "    type_risk = max(type_risks) if type_risks else 0.2\n",
    "    \n",
    "    # Mission sensitivity\n",
    "    mission_sens = 0.0\n",
    "    ms = (\n",
    "        ingest_metadata.get('additional_metadata', {}).get('mission_sensitivity')\n",
    "        or ingest_metadata.get('notes', '')\n",
    "    )\n",
    "    \n",
    "    if ms:\n",
    "        ms_lower = str(ms).lower()\n",
    "        if 'crit' in ms_lower:\n",
    "            mission_sens = 2.0\n",
    "        elif 'high' in ms_lower:\n",
    "            mission_sens = 1.5\n",
    "        elif 'med' in ms_lower:\n",
    "            mission_sens = 1.0\n",
    "    \n",
    "    # Insecure flags penalty\n",
    "    insecure_flags = ingest_metadata.get('insecure_flags', [])\n",
    "    flag_penalty = len(insecure_flags) * 0.5\n",
    "    \n",
    "    # Formula: base + size + type + sensitivity + flags\n",
    "    I_base = 3.0 + (avg_size_mb * 3.0) + (type_risk * 3.0) + mission_sens + flag_penalty\n",
    "    \n",
    "    return round(max(0.0, min(10.0, I_base)), 6)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: COMPUTE ADJUSTED IMPACT (I_prime)\n",
    "# ============================================================================\n",
    "\n",
    "def compute_I_prime(I_base: float, R: float, Z: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute adjusted impact incorporating reputation and zone risk.\n",
    "    \n",
    "    Formula: I' = I_base × (1 + α(1-R)) × (1 + βZ)\n",
    "    \n",
    "    Args:\n",
    "        I_base: Base impact [0, 10]\n",
    "        R: Reputation [0, 1]\n",
    "        Z: Zone risk [0, 1]\n",
    "    \n",
    "    Returns:\n",
    "        Adjusted impact (can exceed 10)\n",
    "    \"\"\"\n",
    "    return I_base * (1 + alpha * (1 - R)) * (1 + beta * Z)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: COMPUTE ADJUSTED DSR (Detection Success Rates)\n",
    "# ============================================================================\n",
    "\n",
    "def compute_DSR_primes(DSR_base_local: Dict[str, float], \n",
    "                       H: float, \n",
    "                       TI: float) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute adjusted detection success rates.\n",
    "    \n",
    "    Formula: DSR'(s) = clamp(DSR(s) × (1 - γH) × (1 + δTI), ε, 1-ε)\n",
    "    \n",
    "    Args:\n",
    "        DSR_base_local: Base detection rates per strategy\n",
    "        H: Infection history [0, 1]\n",
    "        TI: Threat intelligence boost [0, 1]\n",
    "    \n",
    "    Returns:\n",
    "        Adjusted DSR per strategy\n",
    "    \"\"\"\n",
    "    DSR_prime: Dict[str, float] = {}\n",
    "    for s, base in DSR_base_local.items():\n",
    "        val = base * (1 - gamma * H) * (1 + delta * TI)\n",
    "        DSR_prime[s] = clamp(val, eps, 1.0 - eps)\n",
    "    return DSR_prime\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3.5: ADJUST DSR FOR ATTACKER TYPE (NEW - BAYESIAN)\n",
    "# ============================================================================\n",
    "\n",
    "def adjust_DSR_for_attacker_type(DSR_prime: Dict[str, float],\n",
    "                                 attacker_type: AttackerType) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Adjust detection rates based on attacker sophistication.\n",
    "    More sophisticated attackers evade detection better.\n",
    "    \n",
    "    Args:\n",
    "        DSR_prime: Base-adjusted detection rates\n",
    "        attacker_type: Type of attacker\n",
    "    \n",
    "    Returns:\n",
    "        Type-adjusted DSR\n",
    "    \"\"\"\n",
    "    DSR_type_adjusted = {}\n",
    "    for strategy, dsr in DSR_prime.items():\n",
    "        multiplier = attacker_type.dsr_multipliers.get(strategy, 1.0)\n",
    "        adjusted = dsr * multiplier\n",
    "        DSR_type_adjusted[strategy] = clamp(adjusted, eps, 1.0 - eps)\n",
    "    \n",
    "    return DSR_type_adjusted\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: BUILD PAYOFF MATRICES\n",
    "# ============================================================================\n",
    "\n",
    "def build_payoff_matrices(I_prime: float, \n",
    "                         DSR_prime: Dict[str, float]) -> Tuple[List[List[float]], \n",
    "                                                                List[List[float]]]:\n",
    "    \"\"\"\n",
    "    Build payoff matrices for defender and attacker (conservative model).\n",
    "    \n",
    "    Args:\n",
    "        I_prime: Adjusted impact\n",
    "        DSR_prime: Adjusted detection success rates\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (U_a, U_d) - attacker and defender payoff matrices\n",
    "    \"\"\"\n",
    "    U_a: List[List[float]] = []\n",
    "    U_d: List[List[float]] = []\n",
    "    \n",
    "    for s in defender_strats:\n",
    "        dsr = DSR_prime[s]\n",
    "        asp = 1.0 - dsr  # Attacker success probability\n",
    "        \n",
    "        row_a: List[float] = []\n",
    "        row_d: List[float] = []\n",
    "        \n",
    "        for a in attacker_actions:\n",
    "            # Attacker payoff\n",
    "            if a == 'no_inject':\n",
    "                ua = 0.0\n",
    "            else:  # inject\n",
    "                ua = asp * I_prime - C_a[a]\n",
    "            \n",
    "            # Defender payoff (conservative)\n",
    "            if a == 'no_inject':\n",
    "                ud = -C_d[s]  # Pay cost, no benefit\n",
    "            else:  # inject\n",
    "                ud = dsr * I_prime - C_d[s]\n",
    "            \n",
    "            row_a.append(round(ua, 6))\n",
    "            row_d.append(round(ud, 6))\n",
    "        \n",
    "        U_a.append(row_a)\n",
    "        U_d.append(row_d)\n",
    "    \n",
    "    return U_a, U_d\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: SOLVE STACKELBERG EQUILIBRIUM\n",
    "# ============================================================================\n",
    "\n",
    "def solve_stackelberg_pure(U_a: List[List[float]], \n",
    "                          U_d: List[List[float]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Solve pure-strategy Stackelberg game (defender leads).\n",
    "    \n",
    "    Process:\n",
    "    1. For each defender strategy, find attacker's best response\n",
    "    2. Defender chooses strategy that maximizes their payoff\n",
    "    \n",
    "    Args:\n",
    "        U_a: Attacker payoff matrix\n",
    "        U_d: Defender payoff matrix\n",
    "    \n",
    "    Returns:\n",
    "        Equilibrium details including strategies and payoffs\n",
    "    \"\"\"\n",
    "    best_def = None\n",
    "    \n",
    "    for i, row in enumerate(U_a):\n",
    "        # Find attacker's best response(s)\n",
    "        max_ua = max(row)\n",
    "        candidates = [j for j, v in enumerate(row) if abs(v - max_ua) < 1e-12]\n",
    "        \n",
    "        # Tie-breaking: attacker picks action that hurts defender most\n",
    "        if len(candidates) == 1:\n",
    "            j_best = candidates[0]\n",
    "        else:\n",
    "            j_best = min(candidates, key=lambda j: U_d[i][j])\n",
    "        \n",
    "        ua = row[j_best]\n",
    "        ud = U_d[i][j_best]\n",
    "        \n",
    "        # Defender picks best strategy\n",
    "        if best_def is None or ud > best_def['ud']:\n",
    "            best_def = {'di': i, 'aj': j_best, 'ud': ud, 'ua': ua}\n",
    "        elif abs(ud - best_def['ud']) < 1e-12:\n",
    "            # Tie-breaking: prefer lower-cost strategy\n",
    "            if C_d[defender_strats[i]] < C_d[defender_strats[best_def['di']]]:\n",
    "                best_def = {'di': i, 'aj': j_best, 'ud': ud, 'ua': ua}\n",
    "    \n",
    "    if best_def is None:\n",
    "        raise ValueError(\"Empty payoff matrices\")\n",
    "    \n",
    "    return {\n",
    "        'defender_index': best_def['di'],\n",
    "        'attacker_index': best_def['aj'],\n",
    "        'defender_strategy': defender_strats[best_def['di']],\n",
    "        'attacker_action': attacker_actions[best_def['aj']],\n",
    "        'U_d_eq': round(best_def['ud'], 6),\n",
    "        'U_a_eq': round(best_def['ua'], 6)\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: BAYESIAN THREAT ESTIMATION (NEW - MAIN ADDITION)\n",
    "# ============================================================================\n",
    "\n",
    "def compute_bayesian_threat_score(I_prime: float,\n",
    "                                  DSR_prime: Dict[str, float],\n",
    "                                  R: float,\n",
    "                                  attacker_priors: Dict[str, float]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compute threat score using Bayesian game model.\n",
    "    Considers uncertainty about attacker type.\n",
    "    \n",
    "    Args:\n",
    "        I_prime: Adjusted impact\n",
    "        DSR_prime: Base-adjusted detection rates\n",
    "        R: Reputation\n",
    "        attacker_priors: Prior probabilities for each attacker type\n",
    "    \n",
    "    Returns:\n",
    "        Bayesian threat assessment with breakdown by attacker type\n",
    "    \"\"\"\n",
    "    type_results = {}\n",
    "    expected_raw = 0.0\n",
    "    expected_T_S = 0.0\n",
    "    \n",
    "    # For each attacker type, compute Stackelberg equilibrium\n",
    "    for type_name, prior in attacker_priors.items():\n",
    "        attacker_type = ATTACKER_TYPES[type_name]\n",
    "        \n",
    "        # Adjust DSR for this attacker type\n",
    "        DSR_type = adjust_DSR_for_attacker_type(DSR_prime, attacker_type)\n",
    "        \n",
    "        # Build payoff matrices for this type\n",
    "        U_a, U_d = build_payoff_matrices(I_prime, DSR_type)\n",
    "        \n",
    "        # Solve Stackelberg equilibrium for this type\n",
    "        eq = solve_stackelberg_pure(U_a, U_d)\n",
    "        \n",
    "        # Compute threat score for this type\n",
    "        raw = eq['U_a_eq'] - eq['U_d_eq']\n",
    "        T_raw = sigmoid(kappa * raw)\n",
    "        T_S_type = lambda_blend * T_raw + (1.0 - lambda_blend) * (1.0 - R)\n",
    "        T_S_type = max(0.0, min(1.0, T_S_type))\n",
    "        \n",
    "        # Store results for this type\n",
    "        type_results[type_name] = {\n",
    "            'prior': round(prior, 6),\n",
    "            'DSR_adjusted': {k: round(v, 6) for k, v in DSR_type.items()},\n",
    "            'equilibrium': eq,\n",
    "            'raw': round(raw, 6),\n",
    "            'T_S': round(T_S_type, 6),\n",
    "            'sophistication': attacker_type.sophistication\n",
    "        }\n",
    "        \n",
    "        # Accumulate expected values\n",
    "        expected_raw += prior * raw\n",
    "        expected_T_S += prior * T_S_type\n",
    "    \n",
    "    # Determine inspection level from expected threat score\n",
    "    if expected_T_S < th_low:\n",
    "        inspection_level = \"Low\"\n",
    "    elif expected_T_S < th_high:\n",
    "        inspection_level = \"Medium\"\n",
    "    else:\n",
    "        inspection_level = \"High\"\n",
    "    \n",
    "    return {\n",
    "        'T_S_bayesian': round(expected_T_S, 6),\n",
    "        'raw_bayesian': round(expected_raw, 6),\n",
    "        'inspection_level': inspection_level,\n",
    "        'type_breakdown': type_results,\n",
    "        'attacker_priors': attacker_priors\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: FULL PIPELINE - BAYESIAN-STACKELBERG ESTIMATOR\n",
    "# ============================================================================\n",
    "\n",
    "def estimate_threat_bayesian(ingestion: Dict[str, Any],\n",
    "                             reputation_mgr: ReputationManager,\n",
    "                             ti_correlator: ThreatIntelligenceCorrelator) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Complete threat estimation pipeline with Bayesian-Stackelberg game.\n",
    "    \n",
    "    Args:\n",
    "        ingestion: Ingestion metadata + artifact records\n",
    "        reputation_mgr: Reputation management system\n",
    "        ti_correlator: Threat intelligence correlator\n",
    "    \n",
    "    Returns:\n",
    "        Complete threat assessment including Bayesian analysis\n",
    "    \"\"\"\n",
    "    ingest_meta = ingestion['ingest_metadata']\n",
    "    artifacts = ingestion['artifact_records']\n",
    "    \n",
    "    # Extract context\n",
    "    drone_id = ingest_meta['drone_id']\n",
    "    mission_zone = ingest_meta.get('mission_zone', 'default')\n",
    "    insecure_flags = ingest_meta.get('insecure_flags', [])\n",
    "    auth_result = ingest_meta.get('auth_result', 'ok')\n",
    "    \n",
    "    # Get reputation and history\n",
    "    R = reputation_mgr.get_reputation(drone_id)\n",
    "    H = reputation_mgr.get_infection_history(drone_id)\n",
    "    \n",
    "    # Get zone risk\n",
    "    Z = get_zone_risk(mission_zone)\n",
    "    \n",
    "    # Threat intelligence correlation\n",
    "    TI = ti_correlator.correlate(artifacts)\n",
    "    \n",
    "    # Compute base impact\n",
    "    I_base = compute_I_base(artifacts, ingest_meta)\n",
    "    \n",
    "    # Compute adjusted impact\n",
    "    I_prime = compute_I_prime(I_base, R, Z)\n",
    "    \n",
    "    # Compute base-adjusted DSR\n",
    "    DSR_prime = compute_DSR_primes(DSR_base, H, TI)\n",
    "    \n",
    "    # Get attacker type priors (Bayesian component)\n",
    "    attacker_priors = get_attacker_type_priors(mission_zone, insecure_flags, auth_result)\n",
    "    \n",
    "    # Compute Bayesian threat score\n",
    "    bayesian_result = compute_bayesian_threat_score(I_prime, DSR_prime, R, attacker_priors)\n",
    "    \n",
    "    # Also compute standard Stackelberg for comparison\n",
    "    U_a, U_d = build_payoff_matrices(I_prime, DSR_prime)\n",
    "    eq_standard = solve_stackelberg_pure(U_a, U_d)\n",
    "    raw_standard = eq_standard['U_a_eq'] - eq_standard['U_d_eq']\n",
    "    T_raw_standard = sigmoid(kappa * raw_standard)\n",
    "    T_S_standard = lambda_blend * T_raw_standard + (1.0 - lambda_blend) * (1.0 - R)\n",
    "    T_S_standard = max(0.0, min(1.0, T_S_standard))\n",
    "    \n",
    "    if T_S_standard < th_low:\n",
    "        level_standard = \"Low\"\n",
    "    elif T_S_standard < th_high:\n",
    "        level_standard = \"Medium\"\n",
    "    else:\n",
    "        level_standard = \"High\"\n",
    "    \n",
    "    # Return comprehensive results\n",
    "    return {\n",
    "        'ingest_id': ingest_meta.get('ingest_id'),\n",
    "        'drone_id': drone_id,\n",
    "        'timestamp': ingest_meta.get('timestamp'),\n",
    "        \n",
    "        # Input parameters\n",
    "        'inputs': {\n",
    "            'I_base': round(I_base, 6),\n",
    "            'I_prime': round(I_prime, 6),\n",
    "            'R': round(R, 6),\n",
    "            'Z': round(Z, 6),\n",
    "            'H': round(H, 6),\n",
    "            'TI': round(TI, 6),\n",
    "            'DSR_prime': {k: round(v, 6) for k, v in DSR_prime.items()}\n",
    "        },\n",
    "        \n",
    "        # Bayesian results (PRIMARY)\n",
    "        'bayesian': bayesian_result,\n",
    "        \n",
    "        # Standard Stackelberg (for comparison)\n",
    "        'standard_stackelberg': {\n",
    "            'T_S': round(T_S_standard, 6),\n",
    "            'inspection_level': level_standard,\n",
    "            'equilibrium': eq_standard,\n",
    "            'raw': round(raw_standard, 6)\n",
    "        },\n",
    "        \n",
    "        # Model parameters\n",
    "        'parameters': {\n",
    "            'alpha': alpha, 'beta': beta, 'gamma': gamma, 'delta': delta,\n",
    "            'kappa': kappa, 'lambda_blend': lambda_blend,\n",
    "            'th_low': th_low, 'th_high': th_high\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# EXAMPLE USAGE WITH ALL SAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize systems\n",
    "    rep_mgr = ReputationManager()\n",
    "    ti_corr = ThreatIntelligenceCorrelator()\n",
    "    \n",
    "    # Add some sample IOCs\n",
    "    ti_corr.add_ioc(\"9f8e7d6c...\", 0.8)  # High severity IOC\n",
    "    \n",
    "    # Sample data (use your existing samples)\n",
    "    samples = {\n",
    "        'A': {  # Normal feed\n",
    "            \"ingest_metadata\": {\n",
    "                \"ingest_id\": \"ingest_9f1a2b3c4d\",\n",
    "                \"drone_id\": \"DRN-001\",\n",
    "                \"timestamp\": \"2025-10-13T03:00:12Z\",\n",
    "                \"mission_zone\": \"zone-a\",\n",
    "                \"insecure_flags\": [],\n",
    "                \"auth_result\": \"ok\"\n",
    "            },\n",
    "            \"artifact_records\": [\n",
    "                {\"type\": \"video\", \"size_bytes\": 4500000},\n",
    "                {\"type\": \"image\", \"size_bytes\": 320000}\n",
    "            ]\n",
    "        },\n",
    "        'B': {  # Suspicious encrypted\n",
    "            \"ingest_metadata\": {\n",
    "                \"ingest_id\": \"ingest_c7d6e5f4a3\",\n",
    "                \"drone_id\": \"DRN-002\",\n",
    "                \"mission_zone\": \"zone-c\",\n",
    "                \"insecure_flags\": [\"encrypted_payload\", \"nested_archive\"],\n",
    "                \"auth_result\": \"unknown\"\n",
    "            },\n",
    "            \"artifact_records\": [\n",
    "                {\"type\": \"archive\", \"size_bytes\": 4200000, \"encryption\": True, \"container\": True},\n",
    "                {\"type\": \"text\", \"size_bytes\": 2048}\n",
    "            ]\n",
    "        },\n",
    "        'C': {  # Low risk telemetry\n",
    "            \"ingest_metadata\": {\n",
    "                \"ingest_id\": \"ingest_e8f7g6h5i4\",\n",
    "                \"drone_id\": \"DRN-003\",\n",
    "                \"mission_zone\": \"zone-b\",\n",
    "                \"insecure_flags\": [],\n",
    "                \"auth_result\": \"ok\"\n",
    "            },\n",
    "            \"artifact_records\": [\n",
    "                {\"type\": \"telemetry\", \"size_bytes\": 1500}\n",
    "            ]\n",
    "        },\n",
    "        'High-Risk': {  # Critical mission, failed auth\n",
    "            \"ingest_metadata\": {\n",
    "                \"ingest_id\": \"ingest_high_999\",\n",
    "                \"drone_id\": \"DRN-999\",\n",
    "                \"mission_zone\": \"zone-x\",\n",
    "                \"insecure_flags\": [\"encrypted_payload\", \"nested_archive\"],\n",
    "                \"auth_result\": \"fail\",\n",
    "                \"notes\": \"critical mission\"\n",
    "            },\n",
    "            \"artifact_records\": [\n",
    "                {\"type\": \"archive\", \"size_bytes\": 18000000, \"encryption\": True}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"BAYESIAN-STACKELBERG THREAT ESTIMATOR - RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for sample_name, sample_data in samples.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"SAMPLE {sample_name}: {sample_data['ingest_metadata']['drone_id']}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        result = estimate_threat_bayesian(sample_data, rep_mgr, ti_corr)\n",
    "        \n",
    "        # Pretty-print the JSON result\n",
    "        print(json.dumps(result, indent=2))\n",
    "        \n",
    "        # Basic feedback rule for updating reputation (example policy):\n",
    "        # - If Bayesian inspection level is High -> mark as 'malicious'\n",
    "        # - If Medium -> 'suspicious'\n",
    "        # - If Low -> 'clean'\n",
    "        bayes_level = result['bayesian']['inspection_level']\n",
    "        if bayes_level == \"High\":\n",
    "            feedback = 'malicious'\n",
    "        elif bayes_level == \"Medium\":\n",
    "            feedback = 'suspicious'\n",
    "        else:\n",
    "            feedback = 'clean'\n",
    "        \n",
    "        # Update reputation manager with feedback\n",
    "        drone = sample_data['ingest_metadata']['drone_id']\n",
    "        rep_mgr.update_reputation(drone, feedback)\n",
    "        \n",
    "        # Show updated reputation\n",
    "        updated_rep = rep_mgr.get_reputation(drone)\n",
    "        print(f\"\\n[Feedback] Bayesian level={bayes_level} -> updated reputation for {drone}: {updated_rep:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Done. Reputations database snapshot:\")\n",
    "    print(json.dumps(rep_mgr.reputation_db, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "btpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
